{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Minotaor Minotaor is an a mino acid sequence anno ta t or for quickly identifying common protein tags and linkers in an ORF. Additionally, it can flag peptide motifs that are known to cause problems during translation. It uses Biopython. Background In the PROSITE nomenclature, a sequence motif is a description of the occurrence of amino acids (signature, fingerprint), and can be either a pattern or a profile. A pattern is a qualitative description of a motif in a regular expression-like syntax. A profile (or weight matrix) is a table of position-specific amino acid weights and gap costs. Many independent binary classifications can be applied to these motifs: is tag? is linker? is epitope? etc.. Install pip install minotaor Usage import minotaor from Bio.Seq import Seq from Bio.SeqRecord import SeqRecord protein = Seq ( \"SYYHHHHHHHDYPTEGKSSGSGSESKST*EDINBURGHGENQMEFQUNDRY*\" ) protein_record = SeqRecord ( protein , id = \"example\" , annotations = { \"molecule_type\" : \"protein\" }) protein_record = minotaor . annotate_record ( protein_record ) # search is case sensitive Plotting Plotting requires DNA Features Viewer installed: graphic_record = minotaor . MinotaorTranslator () . translate_record ( protein_record ) ax , _ = graphic_record . plot ( figure_width = 10 , strand_in_label_threshold = 7 ) graphic_record . plot_sequence ( ax ) The annotation classes are colored as follows: Tags Linkers Warnings (potential issues, translation pauses etc.) Errors and stop codons All other classes (protein domain, epitope, CDR3 region, motif etc.) Reference datasets Minotaor can use custom reference pandas dataframes, specified with seq_dataset . The sequence and name columns are used for search and naming of the motifs. The type column sets the search type, which can be seq for strings or pattern or regexes (regular expressions). This is shown in the below examples of epitope datasets. Immune Epitope Database Download and unzip a CSV Metric Export of your choice from the IEDB website , then: import pandas iedb_file = 'epitope_full_v3.csv' iedb = pandas . read_csv ( iedb_file , skiprows = 1 , dtype = 'str' ) iedb . rename ( columns = { \"Epitope IRI\" : \"name\" , \"Description\" : \"sequence\" }, inplace = True ) iedb [ 'type' ] = 'seq' # The dataframe can be used as shown above (note: this is a huge dataset): protein_record = minotaor . annotate_record ( protein_record , seq_dataset = iedb ) The epitopes can then be looked up with the link provided as their names. Alternatively, a more informative epitope name can be constructed from the other columns, as shown in the next section. VDJdb Download and unzip the latest VDJdb release , then: import pandas vdjdb_file = 'vdjdb-YYYY-MM-DD/vdjdb.slim.txt' vdjdb = pandas . read_csv ( vdjdb_file , sep = ' \\t ' ) # Create a unique subset of the epitopes: vdjdb_dataset = vdjdb . copy ( deep = True ) vdjdb_dataset . drop_duplicates ( subset = [ 'antigen.gene' ], inplace = True , ignore_index = True ) vdjdb_dataset [ 'sequence' ] = vdjdb_dataset [ 'antigen.epitope' ] # or 'cdr3' for antibodies vdjdb_dataset [ 'type' ] = 'seq' vdjdb_dataset [ 'name' ] = [ 'VDJdb epitope ' + str ( antigen ) for antigen in vdjdb_dataset [ 'antigen.gene' ] . to_list ()] protein_record = minotaor . annotate_record ( protein_record , seq_dataset = vdjdb_dataset ) The motifs then can be looked up in VDJdb for more details. A similar approach can be used for the McPAS-TCR database. iGEM Sequences can also be annotated with parts in the Registry of the International Genetically Engineered Machine (iGEM) Foundation. A FASTA of all parts can be downloaded and prepared into a reference dataset as shown in examples/igem.py . Alternatively, the exported MySQL database can be prepared in a similar way. PROSITE A function is provided for reading ScanProsite results. Query your sequence with Biopython: from Bio.ExPASy import ScanProsite my_seq = 'MYHHHHHHYAGDLPGLMDGAAAGGGA' # cannot contain '*' scanprosite_handle = ScanProsite . scan ( seq = my_seq , mirror = 'https://prosite.expasy.org/' , output = 'xml' ) scanprosite_record = ScanProsite . read ( scanprosite_handle ) protein_record = SeqRecord ( Seq ( my_seq ), id = \"my_seq\" , annotations = { \"molecule_type\" : \"protein\" }) protein_record = minotaor . add_scanprosite_results ( protein_record , scanprosite_record ) Conversion Convert between PROSITE and regex formats: regex = minotaor . convert_prosite_to_regex ( \"<A-[GV]- {PR} -[FYW](2)- {P} (4)-x-x(8)>.\" ) regex # '^A[GV][^PR][FYW]{2}[^P]{4}[^\\\\*][^\\\\*]{8}$' minotaor . convert_regex_to_prosite ( regex ) # '<A-[GV]-{PR}-[FYW](2)-{P}(4)-x-x(8)>.' InterPro InterPro provides functional analysis of protein sequences, using several databases. We can annotate our protein with the results, as shown below: import minotaor from Bio import SearchIO , SeqIO interpro = SearchIO . read ( handle , 'interproscan-xml' ) # handle is an InterProScan xml file seqrecord = SeqIO . read ( \"protein.fasta\" , \"fasta\" ) seqrecord_annotated = minotaor . add_interpro ( seqrecord , interpro , hit_types = [ 'phobius' ]) Short linear motifs (SLiMs) The Eukaryotic Linear Motif (ELM) database is a manually curated collection of experimentally validated SLiMs. The ELM API returns a tab-separated values (TSV) text file that can be used for annotation: seqrecord_annotated = minotaor . add_elm_tsv ( seqrecord , elm_tsv = \"elm.tsv\" ) Alternatively, TSV files of the datasets can be downloaded then edited for use with annotate_record(seqrecord, seq_dataset= ). Note that ELM indexing starts from 1. Other Given a DNA sequence, return amino acid sequences that may contain it: bsmbi_site = \"CGTCTC\" print ( minotaor . convert_dna_to_aa_pattern ( bsmbi_site )) # ['RL', '[DATRSICYNLFPHVG]V[S]', '[SPAT]S[RPLQH]', 'ET', '[MAT*RSPKLEVQGW]R[R]', '[G*R]D[DAVEG]'] Returns a regex for each of the 6 translation frames. Note that the search with regex is case sensitive. Compute % content of selected amino acids: minotaor . add_aa_content ( seqrecord , aa = [ \"D\" , \"E\" ], window_size = 10 , cutoff = 0.3 , name = \"Acidic sequence\" ): Useful for finding proline-rich (P) or acidic sequences (D/E) that may interfere with translation. Versioning Minotaor uses the semantic versioning scheme. License = MIT Minotaor is free software , which means the users have the freedom to run, copy, distribute, study, change and improve the software. Minotaor was written at the Edinburgh Genome Foundry by Peter Vegh and is released under the MIT license.","title":"Home"},{"location":"#minotaor","text":"Minotaor is an a mino acid sequence anno ta t or for quickly identifying common protein tags and linkers in an ORF. Additionally, it can flag peptide motifs that are known to cause problems during translation. It uses Biopython.","title":"Minotaor"},{"location":"#background","text":"In the PROSITE nomenclature, a sequence motif is a description of the occurrence of amino acids (signature, fingerprint), and can be either a pattern or a profile. A pattern is a qualitative description of a motif in a regular expression-like syntax. A profile (or weight matrix) is a table of position-specific amino acid weights and gap costs. Many independent binary classifications can be applied to these motifs: is tag? is linker? is epitope? etc..","title":"Background"},{"location":"#install","text":"pip install minotaor","title":"Install"},{"location":"#usage","text":"import minotaor from Bio.Seq import Seq from Bio.SeqRecord import SeqRecord protein = Seq ( \"SYYHHHHHHHDYPTEGKSSGSGSESKST*EDINBURGHGENQMEFQUNDRY*\" ) protein_record = SeqRecord ( protein , id = \"example\" , annotations = { \"molecule_type\" : \"protein\" }) protein_record = minotaor . annotate_record ( protein_record ) # search is case sensitive","title":"Usage"},{"location":"#plotting","text":"Plotting requires DNA Features Viewer installed: graphic_record = minotaor . MinotaorTranslator () . translate_record ( protein_record ) ax , _ = graphic_record . plot ( figure_width = 10 , strand_in_label_threshold = 7 ) graphic_record . plot_sequence ( ax ) The annotation classes are colored as follows: Tags Linkers Warnings (potential issues, translation pauses etc.) Errors and stop codons All other classes (protein domain, epitope, CDR3 region, motif etc.)","title":"Plotting"},{"location":"#reference-datasets","text":"Minotaor can use custom reference pandas dataframes, specified with seq_dataset . The sequence and name columns are used for search and naming of the motifs. The type column sets the search type, which can be seq for strings or pattern or regexes (regular expressions). This is shown in the below examples of epitope datasets.","title":"Reference datasets"},{"location":"#immune-epitope-database","text":"Download and unzip a CSV Metric Export of your choice from the IEDB website , then: import pandas iedb_file = 'epitope_full_v3.csv' iedb = pandas . read_csv ( iedb_file , skiprows = 1 , dtype = 'str' ) iedb . rename ( columns = { \"Epitope IRI\" : \"name\" , \"Description\" : \"sequence\" }, inplace = True ) iedb [ 'type' ] = 'seq' # The dataframe can be used as shown above (note: this is a huge dataset): protein_record = minotaor . annotate_record ( protein_record , seq_dataset = iedb ) The epitopes can then be looked up with the link provided as their names. Alternatively, a more informative epitope name can be constructed from the other columns, as shown in the next section.","title":"Immune Epitope Database"},{"location":"#vdjdb","text":"Download and unzip the latest VDJdb release , then: import pandas vdjdb_file = 'vdjdb-YYYY-MM-DD/vdjdb.slim.txt' vdjdb = pandas . read_csv ( vdjdb_file , sep = ' \\t ' ) # Create a unique subset of the epitopes: vdjdb_dataset = vdjdb . copy ( deep = True ) vdjdb_dataset . drop_duplicates ( subset = [ 'antigen.gene' ], inplace = True , ignore_index = True ) vdjdb_dataset [ 'sequence' ] = vdjdb_dataset [ 'antigen.epitope' ] # or 'cdr3' for antibodies vdjdb_dataset [ 'type' ] = 'seq' vdjdb_dataset [ 'name' ] = [ 'VDJdb epitope ' + str ( antigen ) for antigen in vdjdb_dataset [ 'antigen.gene' ] . to_list ()] protein_record = minotaor . annotate_record ( protein_record , seq_dataset = vdjdb_dataset ) The motifs then can be looked up in VDJdb for more details. A similar approach can be used for the McPAS-TCR database.","title":"VDJdb"},{"location":"#igem","text":"Sequences can also be annotated with parts in the Registry of the International Genetically Engineered Machine (iGEM) Foundation. A FASTA of all parts can be downloaded and prepared into a reference dataset as shown in examples/igem.py . Alternatively, the exported MySQL database can be prepared in a similar way.","title":"iGEM"},{"location":"#prosite","text":"A function is provided for reading ScanProsite results. Query your sequence with Biopython: from Bio.ExPASy import ScanProsite my_seq = 'MYHHHHHHYAGDLPGLMDGAAAGGGA' # cannot contain '*' scanprosite_handle = ScanProsite . scan ( seq = my_seq , mirror = 'https://prosite.expasy.org/' , output = 'xml' ) scanprosite_record = ScanProsite . read ( scanprosite_handle ) protein_record = SeqRecord ( Seq ( my_seq ), id = \"my_seq\" , annotations = { \"molecule_type\" : \"protein\" }) protein_record = minotaor . add_scanprosite_results ( protein_record , scanprosite_record )","title":"PROSITE"},{"location":"#conversion","text":"Convert between PROSITE and regex formats: regex = minotaor . convert_prosite_to_regex ( \"<A-[GV]- {PR} -[FYW](2)- {P} (4)-x-x(8)>.\" ) regex # '^A[GV][^PR][FYW]{2}[^P]{4}[^\\\\*][^\\\\*]{8}$' minotaor . convert_regex_to_prosite ( regex ) # '<A-[GV]-{PR}-[FYW](2)-{P}(4)-x-x(8)>.'","title":"Conversion"},{"location":"#interpro","text":"InterPro provides functional analysis of protein sequences, using several databases. We can annotate our protein with the results, as shown below: import minotaor from Bio import SearchIO , SeqIO interpro = SearchIO . read ( handle , 'interproscan-xml' ) # handle is an InterProScan xml file seqrecord = SeqIO . read ( \"protein.fasta\" , \"fasta\" ) seqrecord_annotated = minotaor . add_interpro ( seqrecord , interpro , hit_types = [ 'phobius' ])","title":"InterPro"},{"location":"#short-linear-motifs-slims","text":"The Eukaryotic Linear Motif (ELM) database is a manually curated collection of experimentally validated SLiMs. The ELM API returns a tab-separated values (TSV) text file that can be used for annotation: seqrecord_annotated = minotaor . add_elm_tsv ( seqrecord , elm_tsv = \"elm.tsv\" ) Alternatively, TSV files of the datasets can be downloaded then edited for use with annotate_record(seqrecord, seq_dataset= ). Note that ELM indexing starts from 1.","title":"Short linear motifs (SLiMs)"},{"location":"#other","text":"Given a DNA sequence, return amino acid sequences that may contain it: bsmbi_site = \"CGTCTC\" print ( minotaor . convert_dna_to_aa_pattern ( bsmbi_site )) # ['RL', '[DATRSICYNLFPHVG]V[S]', '[SPAT]S[RPLQH]', 'ET', '[MAT*RSPKLEVQGW]R[R]', '[G*R]D[DAVEG]'] Returns a regex for each of the 6 translation frames. Note that the search with regex is case sensitive. Compute % content of selected amino acids: minotaor . add_aa_content ( seqrecord , aa = [ \"D\" , \"E\" ], window_size = 10 , cutoff = 0.3 , name = \"Acidic sequence\" ): Useful for finding proline-rich (P) or acidic sequences (D/E) that may interfere with translation.","title":"Other"},{"location":"#versioning","text":"Minotaor uses the semantic versioning scheme.","title":"Versioning"},{"location":"#license-mit","text":"Minotaor is free software , which means the users have the freedom to run, copy, distribute, study, change and improve the software. Minotaor was written at the Edinburgh Genome Foundry by Peter Vegh and is released under the MIT license.","title":"License = MIT"},{"location":"reference/minotaor/","text":"Module minotaor View Source from .minotaor import ( SEQ_DATA , MinotaorTranslator , annotate_record , create_and_annotate_record , convert_dna_to_aa_pattern , make_regex_from_dna , convert_prosite_to_regex , tokenize_simple_regex , convert_regex_to_prosite , add_scanprosite_results , get_content , evaluate_content , add_aa_content , add_interpro , add_elm_tsv , ) from .version import __version__ Sub-modules minotaor.minotaor minotaor.version","title":"Index"},{"location":"reference/minotaor/#module-minotaor","text":"View Source from .minotaor import ( SEQ_DATA , MinotaorTranslator , annotate_record , create_and_annotate_record , convert_dna_to_aa_pattern , make_regex_from_dna , convert_prosite_to_regex , tokenize_simple_regex , convert_regex_to_prosite , add_scanprosite_results , get_content , evaluate_content , add_aa_content , add_interpro , add_elm_tsv , ) from .version import __version__","title":"Module minotaor"},{"location":"reference/minotaor/#sub-modules","text":"minotaor.minotaor minotaor.version","title":"Sub-modules"},{"location":"reference/minotaor/minotaor/","text":"Module minotaor.minotaor View Source import os import re import pandas from Bio . Seq import Seq from Bio . SeqFeature import SeqFeature , FeatureLocation from Bio . SeqRecord import SeqRecord DATA_DIR = os . path . join ( os . path . dirname ( os . path . realpath ( __ file__ )), \"data\" ) SEQ_DATA = pandas . read_csv ( os . path . join ( DATA_DIR , \"seq.csv\" )) try : from dna_features_viewer import BiopythonTranslator except ImportError : class MinotaorTranslator : \"\"\"Please install dna_features_viewer to use this class.\"\"\" def __ init__ ( self ) : raise Exception ( \"Please install dna_features_viewer to use this class.\" ) else : class MinotaorTranslator ( BiopythonTranslator ) : \"\"\"Custom translator. Color warnings in red, CDS in default color, all other features in blue. \"\"\" def compute_feature_color ( self , feature ) : mino_class = \"mino_class\" if feature . qualifiers [ mino_class ] == \"error\" : return \"red\" elif feature . qualifiers [ mino_class ] == \"warning\" : return \"yellow\" elif feature . qualifiers [ mino_class ] == \"tag\" : return \"tab:blue\" elif feature . qualifiers [ mino_class ] == \"linker\" : return \"tab:cyan\" else : return \"#7245dc\" # default dna_features_viewer color def compute_feature_label ( self , feature ) : try : label = feature . qualifiers [ \"label\" ] except Exception : label = feature . id return label def annotate_record ( seqrecord , seq_dataset = None ) : \"\"\"Annotate a record with entries of a reference sequence dataset. Note that the search is case sensitive. **Parameters** **seqrecord** > SeqRecord to annotate. **seq_dataset** > A minotaor sequence dataset (`pandas.DataFrame`). Default uses the built-in data. \"\"\" if seq_dataset is None : seq_dataset = SEQ_DATA # FLAG NO START : M if str ( seqrecord . seq )[ 0 ] ! = \"M\" : seqrecord . features . append ( SeqFeature ( FeatureLocation ( 0 , 1 ), type= \"misc_feature\" , id= \"no start codon\" , qualifiers= { \"label\" : \"no start codon\" , \"mino_class\" : \"warning\" }, ) ) # FLAG NO END : * if str ( seqrecord . seq )[ - 1 ] ! = \"*\" : seqrecord . features . append ( SeqFeature ( FeatureLocation ( len ( seqrecord ) - 1 , len ( seqrecord )), type= \"misc_feature\" , id= \"not a stop codon\" , qualifiers= { \"label\" : \"not a stop codon\" , \"mino_class\" : \"warning\" }, ) ) # FLAG STOP CODONS : * stop_positions = [ i for i , letter in enumerate ( str ( seqrecord . seq )) if letter == \"*\" ] for position in stop_positions: seqrecord . features . append ( SeqFeature ( FeatureLocation ( position , position + 1 ), type= \"misc_feature\" , id= \"STOP\" , qualifiers= { \"label\" : \"STOP\" , \"mino_class\" : \"error\" }, ) ) # ANNOTATE SEQUENCES if \"class\" in seq_dataset . columns : has_mino_class = True else : has_mino_class = False mino_class = \"default\" sequences = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"seq\" ][ \"sequence\" ]. to_list () names = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"seq\" ][ \"name\" ]. to_list () for index , sequence in enumerate ( sequences ) : len_sequence = len ( sequence ) name = names [ index ] if has_mino_class: mino_class = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"seq\" ][ \"class\" ]. to_list ()[ index ] matches = [ m . start () for m in re . finditer ( re . escape ( sequence ), str ( seqrecord . seq )) ] for match in matches : seqrecord . features . append ( SeqFeature ( FeatureLocation ( match , ( match + len_sequence )), type= \"misc_feature\" , id = name , qualifiers= { \"label\" : name , \"mino_class\" : mino_class }, ) ) # ANNOTATE PATTERNS patterns = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"pattern\" ][ \"sequence\" ]. to_list () names = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"pattern\" ][ \"name\" ]. to_list () for index , pattern in enumerate ( patterns ) : name = names [ index ] if has_mino_class: mino_class = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"pattern\" ][ \"class\" ]. to_list ()[ index ] matches = { m . start () : m . end () for m in re . finditer ( pattern , str ( seqrecord . seq ))} for start , end in matches . items () : seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , end ), type= \"misc_feature\" , id = name , qualifiers= { \"label\" : name , \"mino_class\" : mino_class }, ) ) return seqrecord def create_and_annotate_record ( sequence , seq_dataset = None ) : \"\"\"Create a SeqRecord from an amino acid sequence string. **Parameters** **sequence** > Sequence (`str`). \"\"\" if seq_dataset is None : seq_dataset = SEQ_DATA protein = Seq ( sequence ) protein_record = SeqRecord ( protein , id= \"example\" , annotations= { \"molecule_type\" : \"protein\" } ) protein_record = annotate_record ( protein_record ) return protein_record def convert_dna_to_aa_pattern ( dna ) : \"\"\"Convert a DNA string to a list of patterns representing its translations. **Parameters** **dna** > DNA (`str` of `ATCG`)\"\"\" if len ( dna ) < 3 : raise ValueError ( \"Minimum DNA length is 3\" ) patterns = [] for frame in [ 0 , 1 , 2 ] : aa_dna = dna [ frame :] prefix = dna [ :frame ] modulo = len ( aa_dna ) % 3 # codon length is 3 if modulo ! = 0 : postfix = aa_dna [ - modulo :] aa_dna = aa_dna [:- modulo ] else : postfix = \"\" regex = make_regex_from_dna ( aa_dna , prefix , postfix ) patterns += [ regex ] dna_reverse_complement = str ( Seq ( dna ). reverse_complement ()) for frame in [ 0 , 1 , 2 ] : aa_dna = dna_reverse_complement [ frame :] prefix = dna_reverse_complement [ :frame ] modulo = len ( aa_dna ) % 3 # codon length is 3 if modulo ! = 0 : postfix = aa_dna [ - modulo :] aa_dna = aa_dna [:- modulo ] else : postfix = \"\" regex = make_regex_from_dna ( aa_dna , prefix , postfix ) patterns += [ regex ] return patterns def make_regex_from_dna ( dna , prefix , postfix ) : \"\"\"Convert three DNA strings into a regex. The first DNA string (`dna`) must be divisible by 3, the length of the second (`prefix`) and third (`postfix`) must be 1 or 2. **Parameters** **dna** > DNA (`str` of `ATCG`). **prefix** > DNA (`str` of `ATCG`). **postfix** > DNA (`str` of `ATCG`). \"\"\" aa = str ( Seq ( dna ). translate ()) prefix_regex = create_prefix_regex ( prefix ) postfix_regex = create_postfix_regex ( postfix ) regex = prefix_regex + aa + postfix_regex return regex def create_prefix_regex ( prefix ) : if prefix : prefix_codons = generate_prefix_codons ( prefix ) translated_prefixes = [] for codon in prefix_codons: aa = str ( Seq ( codon ). translate ()) translated_prefixes += [ aa ] translated_prefixes = list ( set ( translated_prefixes )) # remove duplicates prefix_regex = \"\" . join ( translated_prefixes ) prefix_regex = \"[\" + prefix_regex + \"]\" # match 1 else : prefix_regex = \"\" return prefix_regex def create_postfix_regex ( postfix ) : if postfix : postfix_codons = generate_postfix_codons ( postfix ) translated_postfixes = [] for codon in postfix_codons: aa = str ( Seq ( codon ). translate ()) translated_postfixes += [ aa ] translated_postfixes = list ( set ( translated_postfixes )) # remove duplicates postfix_regex = \"\" . join ( translated_postfixes ) postfix_regex = \"[\" + postfix_regex + \"]\" # match 1 else : postfix_regex = \"\" return postfix_regex def generate_prefix_codons ( prefix ) : codons = [] if len ( prefix ) == 1 : for first_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : for second_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : codon = first_letter + second_letter + prefix codons += [ codon ] elif len ( prefix ) == 2 : for first_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : codon = first_letter + prefix codons += [ codon ] else : raise ValueError ( \"Length of prefix must be 1 or 2\" ) return codons def generate_postfix_codons ( postfix ) : codons = [] if len ( postfix ) == 1 : for second_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : for third_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : codon = postfix + second_letter + third_letter codons += [ codon ] elif len ( postfix ) == 2 : for third_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : codon = postfix + third_letter codons += [ codon ] else : raise ValueError ( \"Length of postfix must be 1 or 2\" ) return codons def convert_prosite_to_regex ( prosite_string ) : \"\"\"Convert a PROSITE motif string to a regex string. **Parameters** **prosite_string** > The PROSITE string (`str`). \"\"\" # Implemented with a hack : by replacing characters , instead of using a lexer . # See https : // prosite . expasy . org / prosuser . html#conv_pa for definition . # Remove period that ends the pattern : if prosite_string [ - 1 ] == \".\" : prosite_string = prosite_string [:- 1 ] else : raise ValueError ( \"Invalid format: a period ('.') must end the pattern\" ) # N - and C - terminal restrictions : if \"<\" in prosite_string: N_terminal = True prosite_string = prosite_string . replace ( \"<\" , \"\" ) else : N_terminal = False if \">\" in prosite_string: if prosite_string [ - 1 ] ! = \">\" : raise Exception ( \"'>' inside square brackets is not supported yet\" ) C_terminal = True prosite_string = prosite_string . replace ( \">\" , \"\" ) else : C_terminal = False tokens = prosite_string . split ( \"-\" ) regex_tokens = [] for token in tokens : # Convert 'x' to regex : any amino acid , but don't match stop codons. token = token.replace(\"x\", \"[^\\\\*]\") # Replace braces for exceptions. if token[0] == \"{\": token = token.replace(\"{\", \"[^\") token = token.replace(\"}\", \"]\") # Replace for repetition. Must come after exception replacement. token = token.replace(\"(\", \"{\") token = token.replace(\")\", \"}\") regex_tokens += [token] regex = \"\".join(regex_tokens) if N_terminal: regex = \"^\" + regex if C_terminal: regex += \"$\" return regex def convert_regex_to_prosite(regex): \"\"\"Convert a compatible regex string to a PROSITE motif. **Parameters** **regex** > The regex string (`str`). \"\"\" tokens = tokenize_simple_regex(regex) regex = convert_tokens_to_prosite(tokens) return regex def convert_tokens_to_prosite(tokens): # The first ^ signifies N-terminal position if tokens[0] == \"^\": is_N_terminal = True del tokens[0] else: is_N_terminal = False regex_tokens = [] if tokens[-1] == \"$\": is_C_terminal = True del tokens[-1] else: is_C_terminal = False # These are in reverse order compared to convert_prosite_to_regex(): for token in tokens: # Replace for repetition. Must come before exception replacement. token = token.replace(\"{\", \"(\") token = token.replace(\"}\", \")\") # Replace braces for exceptions. if token[0:2] == \"[^\": token = token.replace(\"[^\", \"{\") token = token.replace(\"]\", \"}\") # Convert wildcard to 'x ' ; but keep repetition ( x , y ) if \"*\" in token : token = token . replace ( \"{\" , \"\" ) token = token . replace ( \"}\" , \"\" ) token = token . replace ( \" \\\\ \", \"\") token = token.replace(\" * \", \" x \") regex_tokens = regex_tokens + [token] regex = tokens[0] for token in regex_tokens[1:]: if token[0] == \" ( \": regex += token else: regex = regex + \" - \" + token if is_N_terminal: regex = \" < \" + regex # < is a prosite symbol if is_C_terminal: regex = regex + \" > \" # > is a prosite symbol # Add period that must end the pattern: regex = regex + \" . \" return regex def tokenize_simple_regex(regex): \"\"\" Lex regex into list of tokens . \"\"\" # As the format of compatible regexes are simple, a tokenizer is implemented here, # instead of using an external lexer with a grammar definition. tokens = [] index = 0 token_boundaries = [] # this collects the start index of each token closing_brackets = {\" [ \": \" ] \", \" { \": \" } \", \" ( \": \" ) \"} is_group = False for index, character in enumerate(regex): if character in \" [{( \": is_group = True token_boundaries += [index] closing_bracket = closing_brackets[character] elif not is_group: token_boundaries += [index] if character in \" ]}) \": if character != closing_bracket: raise Exception(\" Regex incorrect or cannot be converted to PROSITE . \") is_group = False for index, boundary in enumerate(token_boundaries): try: token = regex[boundary : token_boundaries[index + 1]] except IndexError: token = regex[boundary:] # last token tokens += [token] return tokens def add_scanprosite_results(seqrecord, scanprosite_record): for entry in scanprosite_record: start_index = entry[\" start \"] - 1 # convert to Python indexing stop_index = entry[\" stop \"] # prosite range inclusive, Python not name = \" PROSITE : \" + entry[\" signature_ac \"] # key for the prosite ID seqrecord.features.append( SeqFeature( FeatureLocation(start_index, stop_index), type=\" misc_feature \", id=name, qualifiers={\" label \": name, \" mino_class \": \" default \"}, ) ) return seqrecord def get_content(sequence, aa, window_size): \"\"\" Compute proportion of selected amino acids in string . \"\"\" proportions = [] for index in range(0, (len(sequence) - window_size + 1)): subseq = sequence[index : index + window_size] occurrences = 0 for letter in aa: occurrences += subseq.count(letter) proportion = occurrences / window_size proportions += [proportion] return proportions def evaluate_content(sequence, aa, window_size, cutoff): \"\"\" Compute global or local content of selected amino acids . \"\"\" proportions = get_content(sequence, aa, window_size) positions = [] for index, proportion in enumerate(proportions): if proportion >= cutoff: positions += [index] # add to breaches # sum positions: ranges = {} ranges[positions[0]] = positions[0] + window_size # initialize previous = positions[0] for position in positions[1:]: if ranges[previous] >= position: new_end = position + window_size ranges[previous] = new_end # key remains `previous` else: end = position + window_size ranges[position] = end previous = position return positions, ranges def add_aa_content(seqrecord, aa, window_size, cutoff, name=None): \"\"\" Compute and annotate global or local content of selected amino acids . ** Parameters ** **seqrecord * > The amino acid SeqRecord to annotate . **aa** > List of amino acids to search for ( ` list ` ). **window_size** > The search window size ( ` int ` ). **cutoff** > Annotate section with at least this proportion ( between 0 and 1 ). * name** > Annotation label ( ` str ` ). Default : ` >=# % X/Y/Z`. \"\"\" if name is None: name = \" >= \" + str(int(cutoff * 100)) + \" % \" + \"/\".join(aa) sequence = str ( seqrecord . seq ) positions , ranges = evaluate_content ( sequence , aa = aa , window_size = window_size , cutoff = cutoff ) for start , stop in ranges . items () : seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , stop ), type= \"misc_feature\" , id = name , qualifiers= { \"label\" : name , \"mino_class\" : \"warning\" }, ) ) return seqrecord def add_interpro ( seqrecord , interpro , hit_types = None , include_description = True ) : \"\"\"Annotate SeqRecord with InterPro results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **interpro** > `QueryResult` object output of `Bio.SearchIO.read(handle, \" interproscan - xml \")`. **hit_types** > The InterProScan hit types to filter for (`list`). Default includes all. **include_description** > If True, includes description in the label, otherwise only in the `note` qualifier of the SeqRecord. \"\"\" for hit in interpro . hits : if hit_types is None or hit . attributes [ \"Hit type\" ] in hit_types: for fragment in hit . fragments : start = fragment . query_start end = fragment . query_end identifier = \"%s: %s\" % (hit.attributes[\"Hit type\"], fragment.hit_id) if include_description: identifier = identifier + \" \" + fragment . hit_description qualifier = { \"note\" : fragment . hit_description , \"label\" : identifier , \"mino_class\" : \"default\" , } seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , end ), type= \"interpro\" , id = identifier , qualifiers = qualifier , ) ) return seqrecord def add_elm_tsv ( seqrecord , elm_tsv ) : \"\"\"Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **elm_tsv** > Path to TSV file of results (`str`). \"\"\" elm = pandas . read_csv ( elm_tsv , sep= \"\\t\" ) return add_elm ( seqrecord , elm ) def add_elm ( seqrecord , elm ) : \"\"\"Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **elm** > Dataframe of results (`pandas.DataFrame`). \"\"\" for row in elm . itertuples ( index = True , name= \"Pandas\" ) : seqrecord . features . append ( SeqFeature ( FeatureLocation ( row . start - 1 , row . stop - 1 ), # indexing starts from 1 type= \"misc_feature\" , id= \"ELM:\" + row . elm_identifier , qualifiers= { \"label\" : \"ELM:\" + row . elm_identifier , \"mino_class\" : \"default\" , }, ) ) return seqrecord Variables DATA_DIR SEQ_DATA Functions add_aa_content def add_aa_content ( seqrecord , aa , window_size , cutoff , name = None ) Compute and annotate global or local content of selected amino acids. Parameters * seqrecord The amino acid SeqRecord to annotate. aa List of amino acids to search for ( list ). window_size The search window size ( int ). cutoff Annotate section with at least this proportion (between 0 and 1). name * Annotation label ( str ). Default: >=#% X/Y/Z . View Source def add_aa_content ( seqrecord , aa , window_size , cutoff , name = None ) : \" \"\" Compute and annotate global or local content of selected amino acids. **Parameters** **seqrecord* > The amino acid SeqRecord to annotate. **aa** > List of amino acids to search for (`list`). **window_size** > The search window size (`int`). **cutoff** > Annotate section with at least this proportion (between 0 and 1). *name** > Annotation label (`str`). Default: `>=#% X/Y/Z`. \"\" \" if name is None : name = \">=\" + str ( int ( cutoff * 100 )) + \"% \" + \"/\" . join ( aa ) sequence = str ( seqrecord . seq ) positions , ranges = evaluate_content ( sequence , aa = aa , window_size = window_size , cutoff = cutoff ) for start , stop in ranges . items () : seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , stop ), type = \"misc_feature\" , id = name , qualifiers = { \"label\" : name , \"mino_class\" : \"warning\" } , ) ) return seqrecord add_elm def add_elm ( seqrecord , elm ) Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. Parameters seqrecord SeqRecord to annotate. elm Dataframe of results ( pandas.DataFrame ). View Source def add_elm ( seqrecord , elm ) : \" \"\" Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **elm** > Dataframe of results (`pandas.DataFrame`). \"\" \" for row in elm . itertuples ( index = True , name = \"Pandas\" ) : seqrecord . features . append ( SeqFeature ( FeatureLocation ( row . start - 1 , row . stop - 1 ), # indexing starts from 1 type = \"misc_feature\" , id = \"ELM:\" + row . elm_identifier , qualifiers = { \"label\" : \"ELM:\" + row . elm_identifier , \"mino_class\" : \"default\" , } , ) ) return seqrecord add_elm_tsv def add_elm_tsv ( seqrecord , elm_tsv ) Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. Parameters seqrecord SeqRecord to annotate. elm_tsv Path to TSV file of results ( str ). View Source def add_elm_tsv ( seqrecord , elm_tsv ) : \" \"\" Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **elm_tsv** > Path to TSV file of results (`str`). \"\" \" elm = pandas . read_csv ( elm_tsv , sep = \" \\t \" ) return add_elm ( seqrecord , elm ) add_interpro def add_interpro ( seqrecord , interpro , hit_types = None , include_description = True ) Annotate SeqRecord with InterPro results. Parameters seqrecord SeqRecord to annotate. interpro QueryResult object output of Bio.SearchIO.read(handle, \"interproscan-xml\") . hit_types The InterProScan hit types to filter for ( list ). Default includes all. include_description If True, includes description in the label, otherwise only in the note qualifier of the SeqRecord. View Source def add_interpro ( seqrecord , interpro , hit_types = None , include_description = True ) : \" \"\" Annotate SeqRecord with InterPro results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **interpro** > `QueryResult` object output of `Bio.SearchIO.read(handle, \" interproscan - xml \")`. **hit_types** > The InterProScan hit types to filter for (`list`). Default includes all. **include_description** > If True, includes description in the label, otherwise only in the `note` qualifier of the SeqRecord. \"\" \" for hit in interpro . hits : if hit_types is None or hit . attributes [ \"Hit type\" ] in hit_types : for fragment in hit . fragments : start = fragment . query_start end = fragment . query_end identifier = \"%s: %s\" % ( hit . attributes [ \"Hit type\" ] , fragment . hit_id ) if include_description : identifier = identifier + \" \" + fragment . hit_description qualifier = { \"note\" : fragment . hit_description , \"label\" : identifier , \"mino_class\" : \"default\" , } seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , end ), type = \"interpro\" , id = identifier , qualifiers = qualifier , ) ) return seqrecord add_scanprosite_results def add_scanprosite_results ( seqrecord , scanprosite_record ) View Source def add_scanprosite_results ( seqrecord , scanprosite_record ): for entry in scanprosite_record : start_index = entry [ \"start\" ] - 1 # convert to Python indexing stop_index = entry [ \"stop\" ] # prosite range inclusive , Python not name = \"PROSITE:\" + entry [ \"signature_ac\" ] # key for the prosite ID seqrecord . features . append ( SeqFeature ( FeatureLocation ( start_index , stop_index ), type = \"misc_feature\" , id = name , qualifiers = { \"label\" : name , \"mino_class\" : \"default\" } , ) ) return seqrecord annotate_record def annotate_record ( seqrecord , seq_dataset = None ) Annotate a record with entries of a reference sequence dataset. Note that the search is case sensitive. Parameters seqrecord SeqRecord to annotate. seq_dataset A minotaor sequence dataset ( pandas.DataFrame ). Default uses the built-in data. View Source def annotate_record ( seqrecord , seq_dataset = None ) : \"\"\"Annotate a record with entries of a reference sequence dataset. Note that the search is case sensitive. **Parameters** **seqrecord** > SeqRecord to annotate. **seq_dataset** > A minotaor sequence dataset (`pandas.DataFrame`). Default uses the built-in data. \"\"\" if seq_dataset is None : seq_dataset = SEQ_DATA # FLAG NO START : M if str ( seqrecord . seq ) [ 0 ] != \"M\" : seqrecord . features . append ( SeqFeature ( FeatureLocation ( 0 , 1 ), type = \"misc_feature\" , id = \"no start codon\" , qualifiers = { \"label\" : \"no start codon\" , \"mino_class\" : \"warning\" } , ) ) # FLAG NO END : * if str ( seqrecord . seq ) [ -1 ] != \"*\" : seqrecord . features . append ( SeqFeature ( FeatureLocation ( len ( seqrecord ) - 1 , len ( seqrecord )), type = \"misc_feature\" , id = \"not a stop codon\" , qualifiers = { \"label\" : \"not a stop codon\" , \"mino_class\" : \"warning\" } , ) ) # FLAG STOP CODONS : * stop_positions = [ i for i, letter in enumerate(str(seqrecord.seq)) if letter == \"*\" ] for position in stop_positions : seqrecord . features . append ( SeqFeature ( FeatureLocation ( position , position + 1 ), type = \"misc_feature\" , id = \"STOP\" , qualifiers = { \"label\" : \"STOP\" , \"mino_class\" : \"error\" } , ) ) # ANNOTATE SEQUENCES if \"class\" in seq_dataset . columns : has_mino_class = True else : has_mino_class = False mino_class = \"default\" sequences = seq_dataset . loc [ seq_dataset[\"type\" ] == \"seq\" ] [ \"sequence\" ] . to_list () names = seq_dataset . loc [ seq_dataset[\"type\" ] == \"seq\" ] [ \"name\" ] . to_list () for index , sequence in enumerate ( sequences ) : len_sequence = len ( sequence ) name = names [ index ] if has_mino_class : mino_class = seq_dataset . loc [ seq_dataset[\"type\" ] == \"seq\" ] [ \"class\" ] . to_list () [ index ] matches = [ m.start() for m in re.finditer(re.escape(sequence), str(seqrecord.seq)) ] for match in matches : seqrecord . features . append ( SeqFeature ( FeatureLocation ( match , ( match + len_sequence )), type = \"misc_feature\" , id = name , qualifiers = { \"label\" : name , \"mino_class\" : mino_class } , ) ) # ANNOTATE PATTERNS patterns = seq_dataset . loc [ seq_dataset[\"type\" ] == \"pattern\" ] [ \"sequence\" ] . to_list () names = seq_dataset . loc [ seq_dataset[\"type\" ] == \"pattern\" ] [ \"name\" ] . to_list () for index , pattern in enumerate ( patterns ) : name = names [ index ] if has_mino_class : mino_class = seq_dataset . loc [ seq_dataset[\"type\" ] == \"pattern\" ] [ \"class\" ] . to_list () [ index ] matches = { m . start () : m . end () for m in re . finditer ( pattern , str ( seqrecord . seq )) } for start , end in matches . items () : seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , end ), type = \"misc_feature\" , id = name , qualifiers = { \"label\" : name , \"mino_class\" : mino_class } , ) ) return seqrecord convert_dna_to_aa_pattern def convert_dna_to_aa_pattern ( dna ) Convert a DNA string to a list of patterns representing its translations. Parameters dna DNA ( str of ATCG ) View Source def convert_dna_to_aa_pattern ( dna ) : \"\"\"Convert a DNA string to a list of patterns representing its translations. **Parameters** **dna** > DNA (`str` of `ATCG`)\"\"\" if len ( dna ) < 3 : raise ValueError ( \"Minimum DNA length is 3\" ) patterns = [] for frame in [ 0 , 1 , 2 ] : aa_dna = dna [ frame :] prefix = dna [ :frame ] modulo = len ( aa_dna ) % 3 # codon length is 3 if modulo ! = 0 : postfix = aa_dna [ - modulo :] aa_dna = aa_dna [:- modulo ] else : postfix = \"\" regex = make_regex_from_dna ( aa_dna , prefix , postfix ) patterns += [ regex ] dna_reverse_complement = str ( Seq ( dna ). reverse_complement ()) for frame in [ 0 , 1 , 2 ] : aa_dna = dna_reverse_complement [ frame :] prefix = dna_reverse_complement [ :frame ] modulo = len ( aa_dna ) % 3 # codon length is 3 if modulo ! = 0 : postfix = aa_dna [ - modulo :] aa_dna = aa_dna [:- modulo ] else : postfix = \"\" regex = make_regex_from_dna ( aa_dna , prefix , postfix ) patterns += [ regex ] return patterns convert_prosite_to_regex def convert_prosite_to_regex ( prosite_string ) Convert a PROSITE motif string to a regex string. Parameters prosite_string The PROSITE string ( str ). View Source def convert_prosite_to_regex ( prosite_string ) : \"\"\"Convert a PROSITE motif string to a regex string. **Parameters** **prosite_string** > The PROSITE string (`str`). \"\"\" # Implemented with a hack : by replacing characters , instead of using a lexer . # See https : // prosite . expasy . org / prosuser . html#conv_pa for definition . # Remove period that ends the pattern : if prosite_string [ - 1 ] == \".\" : prosite_string = prosite_string [:- 1 ] else : raise ValueError ( \"Invalid format: a period ('.') must end the pattern\" ) # N - and C - terminal restrictions : if \"<\" in prosite_string: N_terminal = True prosite_string = prosite_string . replace ( \"<\" , \"\" ) else : N_terminal = False if \">\" in prosite_string: if prosite_string [ - 1 ] ! = \">\" : raise Exception ( \"'>' inside square brackets is not supported yet\" ) C_terminal = True prosite_string = prosite_string . replace ( \">\" , \"\" ) else : C_terminal = False tokens = prosite_string . split ( \"-\" ) regex_tokens = [] for token in tokens : # Convert 'x' to regex : any amino acid , but don ' t match stop codons . token = token . replace ( \"x\" , \" [ ^\\\\* ] \") # Replace braces for exceptions. if token[0] == \" { \": token = token.replace(\" { \", \" [ ^ \") token = token.replace(\" } \", \" ] \") # Replace for repetition. Must come after exception replacement. token = token.replace(\" ( \", \" { \") token = token.replace(\" ) \", \" } \") regex_tokens += [token] regex = \"\".join(regex_tokens) if N_terminal: regex = \" ^ \" + regex if C_terminal: regex += \" $\" return regex convert_regex_to_prosite def convert_regex_to_prosite ( regex ) Convert a compatible regex string to a PROSITE motif. Parameters regex The regex string ( str ). View Source def convert_regex_to_prosite ( regex ) : \" \"\" Convert a compatible regex string to a PROSITE motif. **Parameters** **regex** > The regex string (`str`). \"\" \" tokens = tokenize_simple_regex ( regex ) regex = convert_tokens_to_prosite ( tokens ) return regex convert_tokens_to_prosite def convert_tokens_to_prosite ( tokens ) View Source def convert_tokens_to_prosite ( tokens ) : # The first ^ signifies N - terminal position if tokens [ 0 ] == \"^\" : is_N_terminal = True del tokens [ 0 ] else : is_N_terminal = False regex_tokens = [] if tokens [ -1 ] == \"$\" : is_C_terminal = True del tokens [ -1 ] else : is_C_terminal = False # These are in reverse order compared to convert_prosite_to_regex () : for token in tokens : # Replace for repetition . Must come before exception replacement . token = token . replace ( \"{\" , \"(\" ) token = token . replace ( \"}\" , \")\" ) # Replace braces for exceptions . if token [ 0:2 ] == \"[^\" : token = token . replace ( \"[^\" , \"{\" ) token = token . replace ( \"]\" , \"}\" ) # Convert wildcard to 'x' ; but keep repetition ( x , y ) if \"*\" in token : token = token . replace ( \"{\" , \"\" ) token = token . replace ( \"}\" , \"\" ) token = token . replace ( \"\\\\\" , \"\" ) token = token . replace ( \"*\" , \"x\" ) regex_tokens = regex_tokens + [ token ] regex = tokens [ 0 ] for token in regex_tokens [ 1: ] : if token [ 0 ] == \"(\" : regex += token else : regex = regex + \"-\" + token if is_N_terminal : regex = \"<\" + regex # < is a prosite symbol if is_C_terminal : regex = regex + \">\" # > is a prosite symbol # Add period that must end the pattern : regex = regex + \".\" return regex create_and_annotate_record def create_and_annotate_record ( sequence , seq_dataset = None ) Create a SeqRecord from an amino acid sequence string. Parameters sequence Sequence ( str ). View Source def create_and_annotate_record ( sequence , seq_dataset = None ) : \" \"\" Create a SeqRecord from an amino acid sequence string. **Parameters** **sequence** > Sequence (`str`). \"\" \" if seq_dataset is None : seq_dataset = SEQ_DATA protein = Seq ( sequence ) protein_record = SeqRecord ( protein , id = \"example\" , annotations = { \"molecule_type\" : \"protein\" } ) protein_record = annotate_record ( protein_record ) return protein_record create_postfix_regex def create_postfix_regex ( postfix ) View Source def create_postfix_regex ( postfix ) : if postfix : postfix_codons = generate_postfix_codons ( postfix ) translated_postfixes = [] for codon in postfix_codons : aa = str ( Seq ( codon ). translate ()) translated_postfixes += [ aa ] translated_postfixes = list ( set ( translated_postfixes )) # remove duplicates postfix_regex = \"\" . join ( translated_postfixes ) postfix_regex = \"[\" + postfix_regex + \"]\" # match 1 else : postfix_regex = \"\" return postfix_regex create_prefix_regex def create_prefix_regex ( prefix ) View Source def create_prefix_regex ( prefix ) : if prefix : prefix_codons = generate_prefix_codons ( prefix ) translated_prefixes = [] for codon in prefix_codons : aa = str ( Seq ( codon ). translate ()) translated_prefixes += [ aa ] translated_prefixes = list ( set ( translated_prefixes )) # remove duplicates prefix_regex = \"\" . join ( translated_prefixes ) prefix_regex = \"[\" + prefix_regex + \"]\" # match 1 else : prefix_regex = \"\" return prefix_regex evaluate_content def evaluate_content ( sequence , aa , window_size , cutoff ) Compute global or local content of selected amino acids. View Source def evaluate_content ( sequence , aa , window_size , cutoff ) : \"\"\"Compute global or local content of selected amino acids.\"\"\" proportions = get_content ( sequence , aa , window_size ) positions = [] for index , proportion in enumerate ( proportions ) : if proportion >= cutoff : positions += [ index ] # add to breaches # sum positions : ranges = {} ranges [ positions[0 ] ] = positions [ 0 ] + window_size # initialize previous = positions [ 0 ] for position in positions [ 1: ] : if ranges [ previous ] >= position : new_end = position + window_size ranges [ previous ] = new_end # key remains ` previous ` else : end = position + window_size ranges [ position ] = end previous = position return positions , ranges generate_postfix_codons def generate_postfix_codons ( postfix ) View Source def generate_postfix_codons ( postfix ) : codons = [] if len ( postfix ) == 1 : for second_letter in [ \"A\", \"T\", \"C\", \"G\" ] : for third_letter in [ \"A\", \"T\", \"C\", \"G\" ] : codon = postfix + second_letter + third_letter codons += [ codon ] elif len ( postfix ) == 2 : for third_letter in [ \"A\", \"T\", \"C\", \"G\" ] : codon = postfix + third_letter codons += [ codon ] else : raise ValueError ( \"Length of postfix must be 1 or 2\" ) return codons generate_prefix_codons def generate_prefix_codons ( prefix ) View Source def generate_prefix_codons ( prefix ) : codons = [] if len ( prefix ) == 1 : for first_letter in [ \"A\", \"T\", \"C\", \"G\" ] : for second_letter in [ \"A\", \"T\", \"C\", \"G\" ] : codon = first_letter + second_letter + prefix codons += [ codon ] elif len ( prefix ) == 2 : for first_letter in [ \"A\", \"T\", \"C\", \"G\" ] : codon = first_letter + prefix codons += [ codon ] else : raise ValueError ( \"Length of prefix must be 1 or 2\" ) return codons get_content def get_content ( sequence , aa , window_size ) Compute proportion of selected amino acids in string. View Source def get_content ( sequence , aa , window_size ) : \"\"\"Compute proportion of selected amino acids in string.\"\"\" proportions = [] for index in range ( 0 , ( len ( sequence ) - window_size + 1 )) : subseq = sequence [ index : index + window_size ] occurrences = 0 for letter in aa : occurrences += subseq . count ( letter ) proportion = occurrences / window_size proportions += [ proportion ] return proportions make_regex_from_dna def make_regex_from_dna ( dna , prefix , postfix ) Convert three DNA strings into a regex. The first DNA string ( dna ) must be divisible by 3, the length of the second ( prefix ) and third ( postfix ) must be 1 or 2. Parameters dna DNA ( str of ATCG ). prefix DNA ( str of ATCG ). postfix DNA ( str of ATCG ). View Source def make_regex_from_dna ( dna , prefix , postfix ) : \" \"\" Convert three DNA strings into a regex. The first DNA string (`dna`) must be divisible by 3, the length of the second (`prefix`) and third (`postfix`) must be 1 or 2. **Parameters** **dna** > DNA (`str` of `ATCG`). **prefix** > DNA (`str` of `ATCG`). **postfix** > DNA (`str` of `ATCG`). \"\" \" aa = str ( Seq ( dna ). translate ()) prefix_regex = create_prefix_regex ( prefix ) postfix_regex = create_postfix_regex ( postfix ) regex = prefix_regex + aa + postfix_regex return regex tokenize_simple_regex def tokenize_simple_regex ( regex ) Lex regex into list of tokens. View Source def tokenize_simple_regex ( regex ) : \"\"\"Lex regex into list of tokens.\"\"\" # As the format of compatible regexes are simple, a tokenizer is implemented here, # instead of using an external lexer with a grammar definition. tokens = [] index = 0 token_boundaries = [] # this collects the start index of each token closing_brackets = { \"[\" : \"]\" , \"{\" : \"}\" , \"(\" : \")\" } is_group = False for index , character in enumerate ( regex ) : if character in \"[{(\" : is_group = True token_boundaries += [ index ] closing_bracket = closing_brackets [ character ] elif not is_group : token_boundaries += [ index ] if character in \"]})\" : if character != closing_bracket : raise Exception ( \"Regex incorrect or cannot be converted to PROSITE.\" ) is_group = False for index , boundary in enumerate ( token_boundaries ) : try : token = regex [ boundary : token_boundaries [ index + 1 ]] except IndexError : token = regex [ boundary :] # last token tokens += [ token ] return tokens Classes MinotaorTranslator class MinotaorTranslator ( features_filters = (), features_properties = None ) Custom translator. Color warnings in red, CDS in default color, all other features in blue. View Source class MinotaorTranslator: \"\"\"Please install dna_features_viewer to use this class.\"\"\" def __init__ ( self ): raise Exception ( \"Please install dna_features_viewer to use this class.\" ) Ancestors (in MRO) dna_features_viewer.BiopythonTranslator.BiopythonTranslator.BiopythonTranslator dna_features_viewer.BiopythonTranslator.BiopythonTranslatorBase.BiopythonTranslatorBase Class variables default_feature_color graphic_record_parameters ignored_features_types label_fields Static methods quick_class_plot def quick_class_plot ( record , figure_width = 12 , ** kwargs ) Allows super quick and dirty plotting of Biopython records. This is really meant for use in a Jupyter/Ipython notebook with the \"%matplotlib inline\" setting. from dna_features_viewer import BiopythonTranslator BiopythonTranslator.quick_plot(my_record) View Source @classmethod def quick_class_plot ( cls , record , figure_width = 12 , ** kwargs ): \"\"\"Allows super quick and dirty plotting of Biopython records. This is really meant for use in a Jupyter/Ipython notebook with the \"%matplotlib inline\" setting. >>> from dna_features_viewer import BiopythonTranslator >>> BiopythonTranslator.quick_plot(my_record) \"\"\" graphic_record = cls () . translate_record ( record ) ax , _ = graphic_record . plot ( figure_width = figure_width , ** kwargs ) return ax Methods compute_feature_box_color def compute_feature_box_color ( self , feature ) Compute a box_color for this feature. View Source def compute_feature_box_color ( self , feature ): \"\"\"Compute a box_color for this feature.\"\"\" return \"auto\" compute_feature_box_linewidth def compute_feature_box_linewidth ( self , feature ) Compute a box_linewidth for this feature. View Source def compute_feature_box_linewidth ( self , feature ): \"\"\"Compute a box_linewidth for this feature.\"\"\" return 0 . 3 compute_feature_color def compute_feature_color ( self , feature ) Compute a color for this feature. If the feature has a color qualifier it will be used. Otherwise, the classe's default_feature_color is used. To change the behaviour, create a subclass of BiopythonTranslator and overwrite this method. View Source def compute_feature_color ( self , feature ) : mino_class = \"mino_class\" if feature . qualifiers [ mino_class ] == \"error\" : return \"red\" elif feature . qualifiers [ mino_class ] == \"warning\" : return \"yellow\" elif feature . qualifiers [ mino_class ] == \"tag\" : return \"tab:blue\" elif feature . qualifiers [ mino_class ] == \"linker\" : return \"tab:cyan\" else : return \"#7245dc\" # default dna_features_viewer color compute_feature_fontdict def compute_feature_fontdict ( self , feature ) Compute a font dict for this feature. View Source def compute_feature_fontdict ( self , feature ): \"\"\"Compute a font dict for this feature.\"\"\" return None compute_feature_html def compute_feature_html ( self , feature ) Gets the 'label' of the feature. View Source def compute_feature_html ( self , feature ): \"\"\"Gets the 'label' of the feature.\"\"\" return self . compute_feature_label ( feature ) compute_feature_label def compute_feature_label ( self , feature ) Compute the label of the feature. View Source def compute_feature_label ( self , feature ): try : label = feature . qualifiers [ \"label\" ] except Exception : label = feature . id return label compute_feature_label_link_color def compute_feature_label_link_color ( self , feature ) Compute the color of the line linking the label to its feature. View Source def compute_feature_label_link_color ( self , feature ): \"\"\"Compute the color of the line linking the label to its feature.\"\"\" return \"black\" compute_feature_legend_text def compute_feature_legend_text ( self , feature ) View Source def compute_feature_legend_text ( self , feature ): return None compute_feature_linewidth def compute_feature_linewidth ( self , feature ) Compute the edge width of the feature's arrow/rectangle. View Source def compute_feature_linewidth ( self , feature ): \"\"\"Compute the edge width of the feature's arrow/rectangle.\"\"\" return 1 . 0 compute_filtered_features def compute_filtered_features ( self , features ) Return the list of features minus the ignored ones. By the method keeps any feature whose type is not in ignored_features_types and for which all filter(f) pass. View Source def compute_filtered_features ( self , features ): \"\"\"Return the list of features minus the ignored ones. By the method keeps any feature whose type is not in ignored_features_types and for which all filter(f) pass. \"\"\" return [ f for f in features if all ([ fl ( f ) for fl in self . features_filters ]) and f . type not in self . ignored_features_types ] quick_plot def quick_plot ( self , record , figure_width = 12 , ** kwargs ) Allows super quick and dirty plotting of Biopython records. This is really meant for use in a Jupyter/Ipython notebook with the \"%matplotlib inline\" setting. from dna_features_viewer import BiopythonTranslator BiopythonTranslator.quick_plot(my_record) View Source def quick_plot ( self , record , figure_width = 12 , ** kwargs ): \"\"\"Allows super quick and dirty plotting of Biopython records. This is really meant for use in a Jupyter/Ipython notebook with the \"%matplotlib inline\" setting. >>> from dna_features_viewer import BiopythonTranslator >>> BiopythonTranslator.quick_plot(my_record) \"\"\" graphic_record = self . translate_record ( record ) ax , _ = graphic_record . plot ( figure_width = figure_width , ** kwargs ) return ax translate_feature def translate_feature ( self , feature ) Translate a Biopython feature into a Dna Features Viewer feature. View Source def translate_feature ( self , feature ): \"\"\"Translate a Biopython feature into a Dna Features Viewer feature.\"\"\" properties = dict ( label = self . compute_feature_label ( feature ), color = self . compute_feature_color ( feature ), html = self . compute_feature_html ( feature ), fontdict = self . compute_feature_fontdict ( feature ), box_linewidth = self . compute_feature_box_linewidth ( feature ), box_color = self . compute_feature_box_color ( feature ), linewidth = self . compute_feature_linewidth ( feature ), label_link_color = self . compute_feature_label_link_color ( feature ), legend_text = self . compute_feature_legend_text ( feature ), ) if self . features_properties is not None : other_properties = self . features_properties if hasattr ( other_properties , \"__call__\" ): other_properties = other_properties ( feature ) properties . update ( other_properties ) return GraphicFeature ( start = feature . location . start , end = feature . location . end , strand = feature . location . strand , ** properties ) translate_record def translate_record ( self , record , record_class = None ) Create a new GraphicRecord from a BioPython Record object. Parameters record A BioPython Record object or the path to a Genbank or a GFF file. record_class The graphic record class to use, e.g. GraphicRecord (default) or CircularGraphicRecord. Strings 'circular' and 'linear' can also be provided. View Source def translate_record ( self , record , record_class = None ) : \"\"\"Create a new GraphicRecord from a BioPython Record object. Parameters ---------- record A BioPython Record object or the path to a Genbank or a GFF file. record_class The graphic record class to use, e.g. GraphicRecord (default) or CircularGraphicRecord. Strings 'circular' and 'linear' can also be provided. \"\"\" classes = { \"linear\" : GraphicRecord , \"circular\" : CircularGraphicRecord , None : GraphicRecord , } if record_class in classes : record_class = classes [ record_class ] if isinstance ( record , str ) or hasattr ( record , \"read\" ) : record = load_record ( record ) filtered_features = self . compute_filtered_features ( record . features ) return record_class ( sequence_length = len ( record ), sequence = str ( record . seq ), features =[ self.translate_feature(feature) for feature in filtered_features if feature.location is not None ] , ** self . graphic_record_parameters )","title":"Minotaor"},{"location":"reference/minotaor/minotaor/#module-minotaorminotaor","text":"View Source import os import re import pandas from Bio . Seq import Seq from Bio . SeqFeature import SeqFeature , FeatureLocation from Bio . SeqRecord import SeqRecord DATA_DIR = os . path . join ( os . path . dirname ( os . path . realpath ( __ file__ )), \"data\" ) SEQ_DATA = pandas . read_csv ( os . path . join ( DATA_DIR , \"seq.csv\" )) try : from dna_features_viewer import BiopythonTranslator except ImportError : class MinotaorTranslator : \"\"\"Please install dna_features_viewer to use this class.\"\"\" def __ init__ ( self ) : raise Exception ( \"Please install dna_features_viewer to use this class.\" ) else : class MinotaorTranslator ( BiopythonTranslator ) : \"\"\"Custom translator. Color warnings in red, CDS in default color, all other features in blue. \"\"\" def compute_feature_color ( self , feature ) : mino_class = \"mino_class\" if feature . qualifiers [ mino_class ] == \"error\" : return \"red\" elif feature . qualifiers [ mino_class ] == \"warning\" : return \"yellow\" elif feature . qualifiers [ mino_class ] == \"tag\" : return \"tab:blue\" elif feature . qualifiers [ mino_class ] == \"linker\" : return \"tab:cyan\" else : return \"#7245dc\" # default dna_features_viewer color def compute_feature_label ( self , feature ) : try : label = feature . qualifiers [ \"label\" ] except Exception : label = feature . id return label def annotate_record ( seqrecord , seq_dataset = None ) : \"\"\"Annotate a record with entries of a reference sequence dataset. Note that the search is case sensitive. **Parameters** **seqrecord** > SeqRecord to annotate. **seq_dataset** > A minotaor sequence dataset (`pandas.DataFrame`). Default uses the built-in data. \"\"\" if seq_dataset is None : seq_dataset = SEQ_DATA # FLAG NO START : M if str ( seqrecord . seq )[ 0 ] ! = \"M\" : seqrecord . features . append ( SeqFeature ( FeatureLocation ( 0 , 1 ), type= \"misc_feature\" , id= \"no start codon\" , qualifiers= { \"label\" : \"no start codon\" , \"mino_class\" : \"warning\" }, ) ) # FLAG NO END : * if str ( seqrecord . seq )[ - 1 ] ! = \"*\" : seqrecord . features . append ( SeqFeature ( FeatureLocation ( len ( seqrecord ) - 1 , len ( seqrecord )), type= \"misc_feature\" , id= \"not a stop codon\" , qualifiers= { \"label\" : \"not a stop codon\" , \"mino_class\" : \"warning\" }, ) ) # FLAG STOP CODONS : * stop_positions = [ i for i , letter in enumerate ( str ( seqrecord . seq )) if letter == \"*\" ] for position in stop_positions: seqrecord . features . append ( SeqFeature ( FeatureLocation ( position , position + 1 ), type= \"misc_feature\" , id= \"STOP\" , qualifiers= { \"label\" : \"STOP\" , \"mino_class\" : \"error\" }, ) ) # ANNOTATE SEQUENCES if \"class\" in seq_dataset . columns : has_mino_class = True else : has_mino_class = False mino_class = \"default\" sequences = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"seq\" ][ \"sequence\" ]. to_list () names = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"seq\" ][ \"name\" ]. to_list () for index , sequence in enumerate ( sequences ) : len_sequence = len ( sequence ) name = names [ index ] if has_mino_class: mino_class = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"seq\" ][ \"class\" ]. to_list ()[ index ] matches = [ m . start () for m in re . finditer ( re . escape ( sequence ), str ( seqrecord . seq )) ] for match in matches : seqrecord . features . append ( SeqFeature ( FeatureLocation ( match , ( match + len_sequence )), type= \"misc_feature\" , id = name , qualifiers= { \"label\" : name , \"mino_class\" : mino_class }, ) ) # ANNOTATE PATTERNS patterns = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"pattern\" ][ \"sequence\" ]. to_list () names = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"pattern\" ][ \"name\" ]. to_list () for index , pattern in enumerate ( patterns ) : name = names [ index ] if has_mino_class: mino_class = seq_dataset . loc [ seq_dataset [ \"type\" ] == \"pattern\" ][ \"class\" ]. to_list ()[ index ] matches = { m . start () : m . end () for m in re . finditer ( pattern , str ( seqrecord . seq ))} for start , end in matches . items () : seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , end ), type= \"misc_feature\" , id = name , qualifiers= { \"label\" : name , \"mino_class\" : mino_class }, ) ) return seqrecord def create_and_annotate_record ( sequence , seq_dataset = None ) : \"\"\"Create a SeqRecord from an amino acid sequence string. **Parameters** **sequence** > Sequence (`str`). \"\"\" if seq_dataset is None : seq_dataset = SEQ_DATA protein = Seq ( sequence ) protein_record = SeqRecord ( protein , id= \"example\" , annotations= { \"molecule_type\" : \"protein\" } ) protein_record = annotate_record ( protein_record ) return protein_record def convert_dna_to_aa_pattern ( dna ) : \"\"\"Convert a DNA string to a list of patterns representing its translations. **Parameters** **dna** > DNA (`str` of `ATCG`)\"\"\" if len ( dna ) < 3 : raise ValueError ( \"Minimum DNA length is 3\" ) patterns = [] for frame in [ 0 , 1 , 2 ] : aa_dna = dna [ frame :] prefix = dna [ :frame ] modulo = len ( aa_dna ) % 3 # codon length is 3 if modulo ! = 0 : postfix = aa_dna [ - modulo :] aa_dna = aa_dna [:- modulo ] else : postfix = \"\" regex = make_regex_from_dna ( aa_dna , prefix , postfix ) patterns += [ regex ] dna_reverse_complement = str ( Seq ( dna ). reverse_complement ()) for frame in [ 0 , 1 , 2 ] : aa_dna = dna_reverse_complement [ frame :] prefix = dna_reverse_complement [ :frame ] modulo = len ( aa_dna ) % 3 # codon length is 3 if modulo ! = 0 : postfix = aa_dna [ - modulo :] aa_dna = aa_dna [:- modulo ] else : postfix = \"\" regex = make_regex_from_dna ( aa_dna , prefix , postfix ) patterns += [ regex ] return patterns def make_regex_from_dna ( dna , prefix , postfix ) : \"\"\"Convert three DNA strings into a regex. The first DNA string (`dna`) must be divisible by 3, the length of the second (`prefix`) and third (`postfix`) must be 1 or 2. **Parameters** **dna** > DNA (`str` of `ATCG`). **prefix** > DNA (`str` of `ATCG`). **postfix** > DNA (`str` of `ATCG`). \"\"\" aa = str ( Seq ( dna ). translate ()) prefix_regex = create_prefix_regex ( prefix ) postfix_regex = create_postfix_regex ( postfix ) regex = prefix_regex + aa + postfix_regex return regex def create_prefix_regex ( prefix ) : if prefix : prefix_codons = generate_prefix_codons ( prefix ) translated_prefixes = [] for codon in prefix_codons: aa = str ( Seq ( codon ). translate ()) translated_prefixes += [ aa ] translated_prefixes = list ( set ( translated_prefixes )) # remove duplicates prefix_regex = \"\" . join ( translated_prefixes ) prefix_regex = \"[\" + prefix_regex + \"]\" # match 1 else : prefix_regex = \"\" return prefix_regex def create_postfix_regex ( postfix ) : if postfix : postfix_codons = generate_postfix_codons ( postfix ) translated_postfixes = [] for codon in postfix_codons: aa = str ( Seq ( codon ). translate ()) translated_postfixes += [ aa ] translated_postfixes = list ( set ( translated_postfixes )) # remove duplicates postfix_regex = \"\" . join ( translated_postfixes ) postfix_regex = \"[\" + postfix_regex + \"]\" # match 1 else : postfix_regex = \"\" return postfix_regex def generate_prefix_codons ( prefix ) : codons = [] if len ( prefix ) == 1 : for first_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : for second_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : codon = first_letter + second_letter + prefix codons += [ codon ] elif len ( prefix ) == 2 : for first_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : codon = first_letter + prefix codons += [ codon ] else : raise ValueError ( \"Length of prefix must be 1 or 2\" ) return codons def generate_postfix_codons ( postfix ) : codons = [] if len ( postfix ) == 1 : for second_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : for third_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : codon = postfix + second_letter + third_letter codons += [ codon ] elif len ( postfix ) == 2 : for third_letter in [ \"A\" , \"T\" , \"C\" , \"G\" ] : codon = postfix + third_letter codons += [ codon ] else : raise ValueError ( \"Length of postfix must be 1 or 2\" ) return codons def convert_prosite_to_regex ( prosite_string ) : \"\"\"Convert a PROSITE motif string to a regex string. **Parameters** **prosite_string** > The PROSITE string (`str`). \"\"\" # Implemented with a hack : by replacing characters , instead of using a lexer . # See https : // prosite . expasy . org / prosuser . html#conv_pa for definition . # Remove period that ends the pattern : if prosite_string [ - 1 ] == \".\" : prosite_string = prosite_string [:- 1 ] else : raise ValueError ( \"Invalid format: a period ('.') must end the pattern\" ) # N - and C - terminal restrictions : if \"<\" in prosite_string: N_terminal = True prosite_string = prosite_string . replace ( \"<\" , \"\" ) else : N_terminal = False if \">\" in prosite_string: if prosite_string [ - 1 ] ! = \">\" : raise Exception ( \"'>' inside square brackets is not supported yet\" ) C_terminal = True prosite_string = prosite_string . replace ( \">\" , \"\" ) else : C_terminal = False tokens = prosite_string . split ( \"-\" ) regex_tokens = [] for token in tokens : # Convert 'x' to regex : any amino acid , but don't match stop codons. token = token.replace(\"x\", \"[^\\\\*]\") # Replace braces for exceptions. if token[0] == \"{\": token = token.replace(\"{\", \"[^\") token = token.replace(\"}\", \"]\") # Replace for repetition. Must come after exception replacement. token = token.replace(\"(\", \"{\") token = token.replace(\")\", \"}\") regex_tokens += [token] regex = \"\".join(regex_tokens) if N_terminal: regex = \"^\" + regex if C_terminal: regex += \"$\" return regex def convert_regex_to_prosite(regex): \"\"\"Convert a compatible regex string to a PROSITE motif. **Parameters** **regex** > The regex string (`str`). \"\"\" tokens = tokenize_simple_regex(regex) regex = convert_tokens_to_prosite(tokens) return regex def convert_tokens_to_prosite(tokens): # The first ^ signifies N-terminal position if tokens[0] == \"^\": is_N_terminal = True del tokens[0] else: is_N_terminal = False regex_tokens = [] if tokens[-1] == \"$\": is_C_terminal = True del tokens[-1] else: is_C_terminal = False # These are in reverse order compared to convert_prosite_to_regex(): for token in tokens: # Replace for repetition. Must come before exception replacement. token = token.replace(\"{\", \"(\") token = token.replace(\"}\", \")\") # Replace braces for exceptions. if token[0:2] == \"[^\": token = token.replace(\"[^\", \"{\") token = token.replace(\"]\", \"}\") # Convert wildcard to 'x ' ; but keep repetition ( x , y ) if \"*\" in token : token = token . replace ( \"{\" , \"\" ) token = token . replace ( \"}\" , \"\" ) token = token . replace ( \" \\\\ \", \"\") token = token.replace(\" * \", \" x \") regex_tokens = regex_tokens + [token] regex = tokens[0] for token in regex_tokens[1:]: if token[0] == \" ( \": regex += token else: regex = regex + \" - \" + token if is_N_terminal: regex = \" < \" + regex # < is a prosite symbol if is_C_terminal: regex = regex + \" > \" # > is a prosite symbol # Add period that must end the pattern: regex = regex + \" . \" return regex def tokenize_simple_regex(regex): \"\"\" Lex regex into list of tokens . \"\"\" # As the format of compatible regexes are simple, a tokenizer is implemented here, # instead of using an external lexer with a grammar definition. tokens = [] index = 0 token_boundaries = [] # this collects the start index of each token closing_brackets = {\" [ \": \" ] \", \" { \": \" } \", \" ( \": \" ) \"} is_group = False for index, character in enumerate(regex): if character in \" [{( \": is_group = True token_boundaries += [index] closing_bracket = closing_brackets[character] elif not is_group: token_boundaries += [index] if character in \" ]}) \": if character != closing_bracket: raise Exception(\" Regex incorrect or cannot be converted to PROSITE . \") is_group = False for index, boundary in enumerate(token_boundaries): try: token = regex[boundary : token_boundaries[index + 1]] except IndexError: token = regex[boundary:] # last token tokens += [token] return tokens def add_scanprosite_results(seqrecord, scanprosite_record): for entry in scanprosite_record: start_index = entry[\" start \"] - 1 # convert to Python indexing stop_index = entry[\" stop \"] # prosite range inclusive, Python not name = \" PROSITE : \" + entry[\" signature_ac \"] # key for the prosite ID seqrecord.features.append( SeqFeature( FeatureLocation(start_index, stop_index), type=\" misc_feature \", id=name, qualifiers={\" label \": name, \" mino_class \": \" default \"}, ) ) return seqrecord def get_content(sequence, aa, window_size): \"\"\" Compute proportion of selected amino acids in string . \"\"\" proportions = [] for index in range(0, (len(sequence) - window_size + 1)): subseq = sequence[index : index + window_size] occurrences = 0 for letter in aa: occurrences += subseq.count(letter) proportion = occurrences / window_size proportions += [proportion] return proportions def evaluate_content(sequence, aa, window_size, cutoff): \"\"\" Compute global or local content of selected amino acids . \"\"\" proportions = get_content(sequence, aa, window_size) positions = [] for index, proportion in enumerate(proportions): if proportion >= cutoff: positions += [index] # add to breaches # sum positions: ranges = {} ranges[positions[0]] = positions[0] + window_size # initialize previous = positions[0] for position in positions[1:]: if ranges[previous] >= position: new_end = position + window_size ranges[previous] = new_end # key remains `previous` else: end = position + window_size ranges[position] = end previous = position return positions, ranges def add_aa_content(seqrecord, aa, window_size, cutoff, name=None): \"\"\" Compute and annotate global or local content of selected amino acids . ** Parameters ** **seqrecord * > The amino acid SeqRecord to annotate . **aa** > List of amino acids to search for ( ` list ` ). **window_size** > The search window size ( ` int ` ). **cutoff** > Annotate section with at least this proportion ( between 0 and 1 ). * name** > Annotation label ( ` str ` ). Default : ` >=# % X/Y/Z`. \"\"\" if name is None: name = \" >= \" + str(int(cutoff * 100)) + \" % \" + \"/\".join(aa) sequence = str ( seqrecord . seq ) positions , ranges = evaluate_content ( sequence , aa = aa , window_size = window_size , cutoff = cutoff ) for start , stop in ranges . items () : seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , stop ), type= \"misc_feature\" , id = name , qualifiers= { \"label\" : name , \"mino_class\" : \"warning\" }, ) ) return seqrecord def add_interpro ( seqrecord , interpro , hit_types = None , include_description = True ) : \"\"\"Annotate SeqRecord with InterPro results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **interpro** > `QueryResult` object output of `Bio.SearchIO.read(handle, \" interproscan - xml \")`. **hit_types** > The InterProScan hit types to filter for (`list`). Default includes all. **include_description** > If True, includes description in the label, otherwise only in the `note` qualifier of the SeqRecord. \"\"\" for hit in interpro . hits : if hit_types is None or hit . attributes [ \"Hit type\" ] in hit_types: for fragment in hit . fragments : start = fragment . query_start end = fragment . query_end identifier = \"%s: %s\" % (hit.attributes[\"Hit type\"], fragment.hit_id) if include_description: identifier = identifier + \" \" + fragment . hit_description qualifier = { \"note\" : fragment . hit_description , \"label\" : identifier , \"mino_class\" : \"default\" , } seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , end ), type= \"interpro\" , id = identifier , qualifiers = qualifier , ) ) return seqrecord def add_elm_tsv ( seqrecord , elm_tsv ) : \"\"\"Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **elm_tsv** > Path to TSV file of results (`str`). \"\"\" elm = pandas . read_csv ( elm_tsv , sep= \"\\t\" ) return add_elm ( seqrecord , elm ) def add_elm ( seqrecord , elm ) : \"\"\"Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **elm** > Dataframe of results (`pandas.DataFrame`). \"\"\" for row in elm . itertuples ( index = True , name= \"Pandas\" ) : seqrecord . features . append ( SeqFeature ( FeatureLocation ( row . start - 1 , row . stop - 1 ), # indexing starts from 1 type= \"misc_feature\" , id= \"ELM:\" + row . elm_identifier , qualifiers= { \"label\" : \"ELM:\" + row . elm_identifier , \"mino_class\" : \"default\" , }, ) ) return seqrecord","title":"Module minotaor.minotaor"},{"location":"reference/minotaor/minotaor/#variables","text":"DATA_DIR SEQ_DATA","title":"Variables"},{"location":"reference/minotaor/minotaor/#functions","text":"","title":"Functions"},{"location":"reference/minotaor/minotaor/#add_aa_content","text":"def add_aa_content ( seqrecord , aa , window_size , cutoff , name = None ) Compute and annotate global or local content of selected amino acids. Parameters * seqrecord The amino acid SeqRecord to annotate. aa List of amino acids to search for ( list ). window_size The search window size ( int ). cutoff Annotate section with at least this proportion (between 0 and 1). name * Annotation label ( str ). Default: >=#% X/Y/Z . View Source def add_aa_content ( seqrecord , aa , window_size , cutoff , name = None ) : \" \"\" Compute and annotate global or local content of selected amino acids. **Parameters** **seqrecord* > The amino acid SeqRecord to annotate. **aa** > List of amino acids to search for (`list`). **window_size** > The search window size (`int`). **cutoff** > Annotate section with at least this proportion (between 0 and 1). *name** > Annotation label (`str`). Default: `>=#% X/Y/Z`. \"\" \" if name is None : name = \">=\" + str ( int ( cutoff * 100 )) + \"% \" + \"/\" . join ( aa ) sequence = str ( seqrecord . seq ) positions , ranges = evaluate_content ( sequence , aa = aa , window_size = window_size , cutoff = cutoff ) for start , stop in ranges . items () : seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , stop ), type = \"misc_feature\" , id = name , qualifiers = { \"label\" : name , \"mino_class\" : \"warning\" } , ) ) return seqrecord","title":"add_aa_content"},{"location":"reference/minotaor/minotaor/#add_elm","text":"def add_elm ( seqrecord , elm ) Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. Parameters seqrecord SeqRecord to annotate. elm Dataframe of results ( pandas.DataFrame ). View Source def add_elm ( seqrecord , elm ) : \" \"\" Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **elm** > Dataframe of results (`pandas.DataFrame`). \"\" \" for row in elm . itertuples ( index = True , name = \"Pandas\" ) : seqrecord . features . append ( SeqFeature ( FeatureLocation ( row . start - 1 , row . stop - 1 ), # indexing starts from 1 type = \"misc_feature\" , id = \"ELM:\" + row . elm_identifier , qualifiers = { \"label\" : \"ELM:\" + row . elm_identifier , \"mino_class\" : \"default\" , } , ) ) return seqrecord","title":"add_elm"},{"location":"reference/minotaor/minotaor/#add_elm_tsv","text":"def add_elm_tsv ( seqrecord , elm_tsv ) Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. Parameters seqrecord SeqRecord to annotate. elm_tsv Path to TSV file of results ( str ). View Source def add_elm_tsv ( seqrecord , elm_tsv ) : \" \"\" Annotate SeqRecord with Eukaryotic Linear Motif (ELM) database search results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **elm_tsv** > Path to TSV file of results (`str`). \"\" \" elm = pandas . read_csv ( elm_tsv , sep = \" \\t \" ) return add_elm ( seqrecord , elm )","title":"add_elm_tsv"},{"location":"reference/minotaor/minotaor/#add_interpro","text":"def add_interpro ( seqrecord , interpro , hit_types = None , include_description = True ) Annotate SeqRecord with InterPro results. Parameters seqrecord SeqRecord to annotate. interpro QueryResult object output of Bio.SearchIO.read(handle, \"interproscan-xml\") . hit_types The InterProScan hit types to filter for ( list ). Default includes all. include_description If True, includes description in the label, otherwise only in the note qualifier of the SeqRecord. View Source def add_interpro ( seqrecord , interpro , hit_types = None , include_description = True ) : \" \"\" Annotate SeqRecord with InterPro results. **Parameters** **seqrecord** > `SeqRecord` to annotate. **interpro** > `QueryResult` object output of `Bio.SearchIO.read(handle, \" interproscan - xml \")`. **hit_types** > The InterProScan hit types to filter for (`list`). Default includes all. **include_description** > If True, includes description in the label, otherwise only in the `note` qualifier of the SeqRecord. \"\" \" for hit in interpro . hits : if hit_types is None or hit . attributes [ \"Hit type\" ] in hit_types : for fragment in hit . fragments : start = fragment . query_start end = fragment . query_end identifier = \"%s: %s\" % ( hit . attributes [ \"Hit type\" ] , fragment . hit_id ) if include_description : identifier = identifier + \" \" + fragment . hit_description qualifier = { \"note\" : fragment . hit_description , \"label\" : identifier , \"mino_class\" : \"default\" , } seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , end ), type = \"interpro\" , id = identifier , qualifiers = qualifier , ) ) return seqrecord","title":"add_interpro"},{"location":"reference/minotaor/minotaor/#add_scanprosite_results","text":"def add_scanprosite_results ( seqrecord , scanprosite_record ) View Source def add_scanprosite_results ( seqrecord , scanprosite_record ): for entry in scanprosite_record : start_index = entry [ \"start\" ] - 1 # convert to Python indexing stop_index = entry [ \"stop\" ] # prosite range inclusive , Python not name = \"PROSITE:\" + entry [ \"signature_ac\" ] # key for the prosite ID seqrecord . features . append ( SeqFeature ( FeatureLocation ( start_index , stop_index ), type = \"misc_feature\" , id = name , qualifiers = { \"label\" : name , \"mino_class\" : \"default\" } , ) ) return seqrecord","title":"add_scanprosite_results"},{"location":"reference/minotaor/minotaor/#annotate_record","text":"def annotate_record ( seqrecord , seq_dataset = None ) Annotate a record with entries of a reference sequence dataset. Note that the search is case sensitive. Parameters seqrecord SeqRecord to annotate. seq_dataset A minotaor sequence dataset ( pandas.DataFrame ). Default uses the built-in data. View Source def annotate_record ( seqrecord , seq_dataset = None ) : \"\"\"Annotate a record with entries of a reference sequence dataset. Note that the search is case sensitive. **Parameters** **seqrecord** > SeqRecord to annotate. **seq_dataset** > A minotaor sequence dataset (`pandas.DataFrame`). Default uses the built-in data. \"\"\" if seq_dataset is None : seq_dataset = SEQ_DATA # FLAG NO START : M if str ( seqrecord . seq ) [ 0 ] != \"M\" : seqrecord . features . append ( SeqFeature ( FeatureLocation ( 0 , 1 ), type = \"misc_feature\" , id = \"no start codon\" , qualifiers = { \"label\" : \"no start codon\" , \"mino_class\" : \"warning\" } , ) ) # FLAG NO END : * if str ( seqrecord . seq ) [ -1 ] != \"*\" : seqrecord . features . append ( SeqFeature ( FeatureLocation ( len ( seqrecord ) - 1 , len ( seqrecord )), type = \"misc_feature\" , id = \"not a stop codon\" , qualifiers = { \"label\" : \"not a stop codon\" , \"mino_class\" : \"warning\" } , ) ) # FLAG STOP CODONS : * stop_positions = [ i for i, letter in enumerate(str(seqrecord.seq)) if letter == \"*\" ] for position in stop_positions : seqrecord . features . append ( SeqFeature ( FeatureLocation ( position , position + 1 ), type = \"misc_feature\" , id = \"STOP\" , qualifiers = { \"label\" : \"STOP\" , \"mino_class\" : \"error\" } , ) ) # ANNOTATE SEQUENCES if \"class\" in seq_dataset . columns : has_mino_class = True else : has_mino_class = False mino_class = \"default\" sequences = seq_dataset . loc [ seq_dataset[\"type\" ] == \"seq\" ] [ \"sequence\" ] . to_list () names = seq_dataset . loc [ seq_dataset[\"type\" ] == \"seq\" ] [ \"name\" ] . to_list () for index , sequence in enumerate ( sequences ) : len_sequence = len ( sequence ) name = names [ index ] if has_mino_class : mino_class = seq_dataset . loc [ seq_dataset[\"type\" ] == \"seq\" ] [ \"class\" ] . to_list () [ index ] matches = [ m.start() for m in re.finditer(re.escape(sequence), str(seqrecord.seq)) ] for match in matches : seqrecord . features . append ( SeqFeature ( FeatureLocation ( match , ( match + len_sequence )), type = \"misc_feature\" , id = name , qualifiers = { \"label\" : name , \"mino_class\" : mino_class } , ) ) # ANNOTATE PATTERNS patterns = seq_dataset . loc [ seq_dataset[\"type\" ] == \"pattern\" ] [ \"sequence\" ] . to_list () names = seq_dataset . loc [ seq_dataset[\"type\" ] == \"pattern\" ] [ \"name\" ] . to_list () for index , pattern in enumerate ( patterns ) : name = names [ index ] if has_mino_class : mino_class = seq_dataset . loc [ seq_dataset[\"type\" ] == \"pattern\" ] [ \"class\" ] . to_list () [ index ] matches = { m . start () : m . end () for m in re . finditer ( pattern , str ( seqrecord . seq )) } for start , end in matches . items () : seqrecord . features . append ( SeqFeature ( FeatureLocation ( start , end ), type = \"misc_feature\" , id = name , qualifiers = { \"label\" : name , \"mino_class\" : mino_class } , ) ) return seqrecord","title":"annotate_record"},{"location":"reference/minotaor/minotaor/#convert_dna_to_aa_pattern","text":"def convert_dna_to_aa_pattern ( dna ) Convert a DNA string to a list of patterns representing its translations. Parameters dna DNA ( str of ATCG ) View Source def convert_dna_to_aa_pattern ( dna ) : \"\"\"Convert a DNA string to a list of patterns representing its translations. **Parameters** **dna** > DNA (`str` of `ATCG`)\"\"\" if len ( dna ) < 3 : raise ValueError ( \"Minimum DNA length is 3\" ) patterns = [] for frame in [ 0 , 1 , 2 ] : aa_dna = dna [ frame :] prefix = dna [ :frame ] modulo = len ( aa_dna ) % 3 # codon length is 3 if modulo ! = 0 : postfix = aa_dna [ - modulo :] aa_dna = aa_dna [:- modulo ] else : postfix = \"\" regex = make_regex_from_dna ( aa_dna , prefix , postfix ) patterns += [ regex ] dna_reverse_complement = str ( Seq ( dna ). reverse_complement ()) for frame in [ 0 , 1 , 2 ] : aa_dna = dna_reverse_complement [ frame :] prefix = dna_reverse_complement [ :frame ] modulo = len ( aa_dna ) % 3 # codon length is 3 if modulo ! = 0 : postfix = aa_dna [ - modulo :] aa_dna = aa_dna [:- modulo ] else : postfix = \"\" regex = make_regex_from_dna ( aa_dna , prefix , postfix ) patterns += [ regex ] return patterns","title":"convert_dna_to_aa_pattern"},{"location":"reference/minotaor/minotaor/#convert_prosite_to_regex","text":"def convert_prosite_to_regex ( prosite_string ) Convert a PROSITE motif string to a regex string. Parameters prosite_string The PROSITE string ( str ). View Source def convert_prosite_to_regex ( prosite_string ) : \"\"\"Convert a PROSITE motif string to a regex string. **Parameters** **prosite_string** > The PROSITE string (`str`). \"\"\" # Implemented with a hack : by replacing characters , instead of using a lexer . # See https : // prosite . expasy . org / prosuser . html#conv_pa for definition . # Remove period that ends the pattern : if prosite_string [ - 1 ] == \".\" : prosite_string = prosite_string [:- 1 ] else : raise ValueError ( \"Invalid format: a period ('.') must end the pattern\" ) # N - and C - terminal restrictions : if \"<\" in prosite_string: N_terminal = True prosite_string = prosite_string . replace ( \"<\" , \"\" ) else : N_terminal = False if \">\" in prosite_string: if prosite_string [ - 1 ] ! = \">\" : raise Exception ( \"'>' inside square brackets is not supported yet\" ) C_terminal = True prosite_string = prosite_string . replace ( \">\" , \"\" ) else : C_terminal = False tokens = prosite_string . split ( \"-\" ) regex_tokens = [] for token in tokens : # Convert 'x' to regex : any amino acid , but don ' t match stop codons . token = token . replace ( \"x\" , \" [ ^\\\\* ] \") # Replace braces for exceptions. if token[0] == \" { \": token = token.replace(\" { \", \" [ ^ \") token = token.replace(\" } \", \" ] \") # Replace for repetition. Must come after exception replacement. token = token.replace(\" ( \", \" { \") token = token.replace(\" ) \", \" } \") regex_tokens += [token] regex = \"\".join(regex_tokens) if N_terminal: regex = \" ^ \" + regex if C_terminal: regex += \" $\" return regex","title":"convert_prosite_to_regex"},{"location":"reference/minotaor/minotaor/#convert_regex_to_prosite","text":"def convert_regex_to_prosite ( regex ) Convert a compatible regex string to a PROSITE motif. Parameters regex The regex string ( str ). View Source def convert_regex_to_prosite ( regex ) : \" \"\" Convert a compatible regex string to a PROSITE motif. **Parameters** **regex** > The regex string (`str`). \"\" \" tokens = tokenize_simple_regex ( regex ) regex = convert_tokens_to_prosite ( tokens ) return regex","title":"convert_regex_to_prosite"},{"location":"reference/minotaor/minotaor/#convert_tokens_to_prosite","text":"def convert_tokens_to_prosite ( tokens ) View Source def convert_tokens_to_prosite ( tokens ) : # The first ^ signifies N - terminal position if tokens [ 0 ] == \"^\" : is_N_terminal = True del tokens [ 0 ] else : is_N_terminal = False regex_tokens = [] if tokens [ -1 ] == \"$\" : is_C_terminal = True del tokens [ -1 ] else : is_C_terminal = False # These are in reverse order compared to convert_prosite_to_regex () : for token in tokens : # Replace for repetition . Must come before exception replacement . token = token . replace ( \"{\" , \"(\" ) token = token . replace ( \"}\" , \")\" ) # Replace braces for exceptions . if token [ 0:2 ] == \"[^\" : token = token . replace ( \"[^\" , \"{\" ) token = token . replace ( \"]\" , \"}\" ) # Convert wildcard to 'x' ; but keep repetition ( x , y ) if \"*\" in token : token = token . replace ( \"{\" , \"\" ) token = token . replace ( \"}\" , \"\" ) token = token . replace ( \"\\\\\" , \"\" ) token = token . replace ( \"*\" , \"x\" ) regex_tokens = regex_tokens + [ token ] regex = tokens [ 0 ] for token in regex_tokens [ 1: ] : if token [ 0 ] == \"(\" : regex += token else : regex = regex + \"-\" + token if is_N_terminal : regex = \"<\" + regex # < is a prosite symbol if is_C_terminal : regex = regex + \">\" # > is a prosite symbol # Add period that must end the pattern : regex = regex + \".\" return regex","title":"convert_tokens_to_prosite"},{"location":"reference/minotaor/minotaor/#create_and_annotate_record","text":"def create_and_annotate_record ( sequence , seq_dataset = None ) Create a SeqRecord from an amino acid sequence string. Parameters sequence Sequence ( str ). View Source def create_and_annotate_record ( sequence , seq_dataset = None ) : \" \"\" Create a SeqRecord from an amino acid sequence string. **Parameters** **sequence** > Sequence (`str`). \"\" \" if seq_dataset is None : seq_dataset = SEQ_DATA protein = Seq ( sequence ) protein_record = SeqRecord ( protein , id = \"example\" , annotations = { \"molecule_type\" : \"protein\" } ) protein_record = annotate_record ( protein_record ) return protein_record","title":"create_and_annotate_record"},{"location":"reference/minotaor/minotaor/#create_postfix_regex","text":"def create_postfix_regex ( postfix ) View Source def create_postfix_regex ( postfix ) : if postfix : postfix_codons = generate_postfix_codons ( postfix ) translated_postfixes = [] for codon in postfix_codons : aa = str ( Seq ( codon ). translate ()) translated_postfixes += [ aa ] translated_postfixes = list ( set ( translated_postfixes )) # remove duplicates postfix_regex = \"\" . join ( translated_postfixes ) postfix_regex = \"[\" + postfix_regex + \"]\" # match 1 else : postfix_regex = \"\" return postfix_regex","title":"create_postfix_regex"},{"location":"reference/minotaor/minotaor/#create_prefix_regex","text":"def create_prefix_regex ( prefix ) View Source def create_prefix_regex ( prefix ) : if prefix : prefix_codons = generate_prefix_codons ( prefix ) translated_prefixes = [] for codon in prefix_codons : aa = str ( Seq ( codon ). translate ()) translated_prefixes += [ aa ] translated_prefixes = list ( set ( translated_prefixes )) # remove duplicates prefix_regex = \"\" . join ( translated_prefixes ) prefix_regex = \"[\" + prefix_regex + \"]\" # match 1 else : prefix_regex = \"\" return prefix_regex","title":"create_prefix_regex"},{"location":"reference/minotaor/minotaor/#evaluate_content","text":"def evaluate_content ( sequence , aa , window_size , cutoff ) Compute global or local content of selected amino acids. View Source def evaluate_content ( sequence , aa , window_size , cutoff ) : \"\"\"Compute global or local content of selected amino acids.\"\"\" proportions = get_content ( sequence , aa , window_size ) positions = [] for index , proportion in enumerate ( proportions ) : if proportion >= cutoff : positions += [ index ] # add to breaches # sum positions : ranges = {} ranges [ positions[0 ] ] = positions [ 0 ] + window_size # initialize previous = positions [ 0 ] for position in positions [ 1: ] : if ranges [ previous ] >= position : new_end = position + window_size ranges [ previous ] = new_end # key remains ` previous ` else : end = position + window_size ranges [ position ] = end previous = position return positions , ranges","title":"evaluate_content"},{"location":"reference/minotaor/minotaor/#generate_postfix_codons","text":"def generate_postfix_codons ( postfix ) View Source def generate_postfix_codons ( postfix ) : codons = [] if len ( postfix ) == 1 : for second_letter in [ \"A\", \"T\", \"C\", \"G\" ] : for third_letter in [ \"A\", \"T\", \"C\", \"G\" ] : codon = postfix + second_letter + third_letter codons += [ codon ] elif len ( postfix ) == 2 : for third_letter in [ \"A\", \"T\", \"C\", \"G\" ] : codon = postfix + third_letter codons += [ codon ] else : raise ValueError ( \"Length of postfix must be 1 or 2\" ) return codons","title":"generate_postfix_codons"},{"location":"reference/minotaor/minotaor/#generate_prefix_codons","text":"def generate_prefix_codons ( prefix ) View Source def generate_prefix_codons ( prefix ) : codons = [] if len ( prefix ) == 1 : for first_letter in [ \"A\", \"T\", \"C\", \"G\" ] : for second_letter in [ \"A\", \"T\", \"C\", \"G\" ] : codon = first_letter + second_letter + prefix codons += [ codon ] elif len ( prefix ) == 2 : for first_letter in [ \"A\", \"T\", \"C\", \"G\" ] : codon = first_letter + prefix codons += [ codon ] else : raise ValueError ( \"Length of prefix must be 1 or 2\" ) return codons","title":"generate_prefix_codons"},{"location":"reference/minotaor/minotaor/#get_content","text":"def get_content ( sequence , aa , window_size ) Compute proportion of selected amino acids in string. View Source def get_content ( sequence , aa , window_size ) : \"\"\"Compute proportion of selected amino acids in string.\"\"\" proportions = [] for index in range ( 0 , ( len ( sequence ) - window_size + 1 )) : subseq = sequence [ index : index + window_size ] occurrences = 0 for letter in aa : occurrences += subseq . count ( letter ) proportion = occurrences / window_size proportions += [ proportion ] return proportions","title":"get_content"},{"location":"reference/minotaor/minotaor/#make_regex_from_dna","text":"def make_regex_from_dna ( dna , prefix , postfix ) Convert three DNA strings into a regex. The first DNA string ( dna ) must be divisible by 3, the length of the second ( prefix ) and third ( postfix ) must be 1 or 2. Parameters dna DNA ( str of ATCG ). prefix DNA ( str of ATCG ). postfix DNA ( str of ATCG ). View Source def make_regex_from_dna ( dna , prefix , postfix ) : \" \"\" Convert three DNA strings into a regex. The first DNA string (`dna`) must be divisible by 3, the length of the second (`prefix`) and third (`postfix`) must be 1 or 2. **Parameters** **dna** > DNA (`str` of `ATCG`). **prefix** > DNA (`str` of `ATCG`). **postfix** > DNA (`str` of `ATCG`). \"\" \" aa = str ( Seq ( dna ). translate ()) prefix_regex = create_prefix_regex ( prefix ) postfix_regex = create_postfix_regex ( postfix ) regex = prefix_regex + aa + postfix_regex return regex","title":"make_regex_from_dna"},{"location":"reference/minotaor/minotaor/#tokenize_simple_regex","text":"def tokenize_simple_regex ( regex ) Lex regex into list of tokens. View Source def tokenize_simple_regex ( regex ) : \"\"\"Lex regex into list of tokens.\"\"\" # As the format of compatible regexes are simple, a tokenizer is implemented here, # instead of using an external lexer with a grammar definition. tokens = [] index = 0 token_boundaries = [] # this collects the start index of each token closing_brackets = { \"[\" : \"]\" , \"{\" : \"}\" , \"(\" : \")\" } is_group = False for index , character in enumerate ( regex ) : if character in \"[{(\" : is_group = True token_boundaries += [ index ] closing_bracket = closing_brackets [ character ] elif not is_group : token_boundaries += [ index ] if character in \"]})\" : if character != closing_bracket : raise Exception ( \"Regex incorrect or cannot be converted to PROSITE.\" ) is_group = False for index , boundary in enumerate ( token_boundaries ) : try : token = regex [ boundary : token_boundaries [ index + 1 ]] except IndexError : token = regex [ boundary :] # last token tokens += [ token ] return tokens","title":"tokenize_simple_regex"},{"location":"reference/minotaor/minotaor/#classes","text":"","title":"Classes"},{"location":"reference/minotaor/minotaor/#minotaortranslator","text":"class MinotaorTranslator ( features_filters = (), features_properties = None ) Custom translator. Color warnings in red, CDS in default color, all other features in blue. View Source class MinotaorTranslator: \"\"\"Please install dna_features_viewer to use this class.\"\"\" def __init__ ( self ): raise Exception ( \"Please install dna_features_viewer to use this class.\" )","title":"MinotaorTranslator"},{"location":"reference/minotaor/minotaor/#ancestors-in-mro","text":"dna_features_viewer.BiopythonTranslator.BiopythonTranslator.BiopythonTranslator dna_features_viewer.BiopythonTranslator.BiopythonTranslatorBase.BiopythonTranslatorBase","title":"Ancestors (in MRO)"},{"location":"reference/minotaor/minotaor/#class-variables","text":"default_feature_color graphic_record_parameters ignored_features_types label_fields","title":"Class variables"},{"location":"reference/minotaor/minotaor/#static-methods","text":"","title":"Static methods"},{"location":"reference/minotaor/minotaor/#quick_class_plot","text":"def quick_class_plot ( record , figure_width = 12 , ** kwargs ) Allows super quick and dirty plotting of Biopython records. This is really meant for use in a Jupyter/Ipython notebook with the \"%matplotlib inline\" setting. from dna_features_viewer import BiopythonTranslator BiopythonTranslator.quick_plot(my_record) View Source @classmethod def quick_class_plot ( cls , record , figure_width = 12 , ** kwargs ): \"\"\"Allows super quick and dirty plotting of Biopython records. This is really meant for use in a Jupyter/Ipython notebook with the \"%matplotlib inline\" setting. >>> from dna_features_viewer import BiopythonTranslator >>> BiopythonTranslator.quick_plot(my_record) \"\"\" graphic_record = cls () . translate_record ( record ) ax , _ = graphic_record . plot ( figure_width = figure_width , ** kwargs ) return ax","title":"quick_class_plot"},{"location":"reference/minotaor/minotaor/#methods","text":"","title":"Methods"},{"location":"reference/minotaor/minotaor/#compute_feature_box_color","text":"def compute_feature_box_color ( self , feature ) Compute a box_color for this feature. View Source def compute_feature_box_color ( self , feature ): \"\"\"Compute a box_color for this feature.\"\"\" return \"auto\"","title":"compute_feature_box_color"},{"location":"reference/minotaor/minotaor/#compute_feature_box_linewidth","text":"def compute_feature_box_linewidth ( self , feature ) Compute a box_linewidth for this feature. View Source def compute_feature_box_linewidth ( self , feature ): \"\"\"Compute a box_linewidth for this feature.\"\"\" return 0 . 3","title":"compute_feature_box_linewidth"},{"location":"reference/minotaor/minotaor/#compute_feature_color","text":"def compute_feature_color ( self , feature ) Compute a color for this feature. If the feature has a color qualifier it will be used. Otherwise, the classe's default_feature_color is used. To change the behaviour, create a subclass of BiopythonTranslator and overwrite this method. View Source def compute_feature_color ( self , feature ) : mino_class = \"mino_class\" if feature . qualifiers [ mino_class ] == \"error\" : return \"red\" elif feature . qualifiers [ mino_class ] == \"warning\" : return \"yellow\" elif feature . qualifiers [ mino_class ] == \"tag\" : return \"tab:blue\" elif feature . qualifiers [ mino_class ] == \"linker\" : return \"tab:cyan\" else : return \"#7245dc\" # default dna_features_viewer color","title":"compute_feature_color"},{"location":"reference/minotaor/minotaor/#compute_feature_fontdict","text":"def compute_feature_fontdict ( self , feature ) Compute a font dict for this feature. View Source def compute_feature_fontdict ( self , feature ): \"\"\"Compute a font dict for this feature.\"\"\" return None","title":"compute_feature_fontdict"},{"location":"reference/minotaor/minotaor/#compute_feature_html","text":"def compute_feature_html ( self , feature ) Gets the 'label' of the feature. View Source def compute_feature_html ( self , feature ): \"\"\"Gets the 'label' of the feature.\"\"\" return self . compute_feature_label ( feature )","title":"compute_feature_html"},{"location":"reference/minotaor/minotaor/#compute_feature_label","text":"def compute_feature_label ( self , feature ) Compute the label of the feature. View Source def compute_feature_label ( self , feature ): try : label = feature . qualifiers [ \"label\" ] except Exception : label = feature . id return label","title":"compute_feature_label"},{"location":"reference/minotaor/minotaor/#compute_feature_label_link_color","text":"def compute_feature_label_link_color ( self , feature ) Compute the color of the line linking the label to its feature. View Source def compute_feature_label_link_color ( self , feature ): \"\"\"Compute the color of the line linking the label to its feature.\"\"\" return \"black\"","title":"compute_feature_label_link_color"},{"location":"reference/minotaor/minotaor/#compute_feature_legend_text","text":"def compute_feature_legend_text ( self , feature ) View Source def compute_feature_legend_text ( self , feature ): return None","title":"compute_feature_legend_text"},{"location":"reference/minotaor/minotaor/#compute_feature_linewidth","text":"def compute_feature_linewidth ( self , feature ) Compute the edge width of the feature's arrow/rectangle. View Source def compute_feature_linewidth ( self , feature ): \"\"\"Compute the edge width of the feature's arrow/rectangle.\"\"\" return 1 . 0","title":"compute_feature_linewidth"},{"location":"reference/minotaor/minotaor/#compute_filtered_features","text":"def compute_filtered_features ( self , features ) Return the list of features minus the ignored ones. By the method keeps any feature whose type is not in ignored_features_types and for which all filter(f) pass. View Source def compute_filtered_features ( self , features ): \"\"\"Return the list of features minus the ignored ones. By the method keeps any feature whose type is not in ignored_features_types and for which all filter(f) pass. \"\"\" return [ f for f in features if all ([ fl ( f ) for fl in self . features_filters ]) and f . type not in self . ignored_features_types ]","title":"compute_filtered_features"},{"location":"reference/minotaor/minotaor/#quick_plot","text":"def quick_plot ( self , record , figure_width = 12 , ** kwargs ) Allows super quick and dirty plotting of Biopython records. This is really meant for use in a Jupyter/Ipython notebook with the \"%matplotlib inline\" setting. from dna_features_viewer import BiopythonTranslator BiopythonTranslator.quick_plot(my_record) View Source def quick_plot ( self , record , figure_width = 12 , ** kwargs ): \"\"\"Allows super quick and dirty plotting of Biopython records. This is really meant for use in a Jupyter/Ipython notebook with the \"%matplotlib inline\" setting. >>> from dna_features_viewer import BiopythonTranslator >>> BiopythonTranslator.quick_plot(my_record) \"\"\" graphic_record = self . translate_record ( record ) ax , _ = graphic_record . plot ( figure_width = figure_width , ** kwargs ) return ax","title":"quick_plot"},{"location":"reference/minotaor/minotaor/#translate_feature","text":"def translate_feature ( self , feature ) Translate a Biopython feature into a Dna Features Viewer feature. View Source def translate_feature ( self , feature ): \"\"\"Translate a Biopython feature into a Dna Features Viewer feature.\"\"\" properties = dict ( label = self . compute_feature_label ( feature ), color = self . compute_feature_color ( feature ), html = self . compute_feature_html ( feature ), fontdict = self . compute_feature_fontdict ( feature ), box_linewidth = self . compute_feature_box_linewidth ( feature ), box_color = self . compute_feature_box_color ( feature ), linewidth = self . compute_feature_linewidth ( feature ), label_link_color = self . compute_feature_label_link_color ( feature ), legend_text = self . compute_feature_legend_text ( feature ), ) if self . features_properties is not None : other_properties = self . features_properties if hasattr ( other_properties , \"__call__\" ): other_properties = other_properties ( feature ) properties . update ( other_properties ) return GraphicFeature ( start = feature . location . start , end = feature . location . end , strand = feature . location . strand , ** properties )","title":"translate_feature"},{"location":"reference/minotaor/minotaor/#translate_record","text":"def translate_record ( self , record , record_class = None ) Create a new GraphicRecord from a BioPython Record object.","title":"translate_record"},{"location":"reference/minotaor/minotaor/#parameters","text":"record A BioPython Record object or the path to a Genbank or a GFF file. record_class The graphic record class to use, e.g. GraphicRecord (default) or CircularGraphicRecord. Strings 'circular' and 'linear' can also be provided. View Source def translate_record ( self , record , record_class = None ) : \"\"\"Create a new GraphicRecord from a BioPython Record object. Parameters ---------- record A BioPython Record object or the path to a Genbank or a GFF file. record_class The graphic record class to use, e.g. GraphicRecord (default) or CircularGraphicRecord. Strings 'circular' and 'linear' can also be provided. \"\"\" classes = { \"linear\" : GraphicRecord , \"circular\" : CircularGraphicRecord , None : GraphicRecord , } if record_class in classes : record_class = classes [ record_class ] if isinstance ( record , str ) or hasattr ( record , \"read\" ) : record = load_record ( record ) filtered_features = self . compute_filtered_features ( record . features ) return record_class ( sequence_length = len ( record ), sequence = str ( record . seq ), features =[ self.translate_feature(feature) for feature in filtered_features if feature.location is not None ] , ** self . graphic_record_parameters )","title":"Parameters"},{"location":"reference/minotaor/version/","text":"Module minotaor.version View Source __version__ = \"0.1.2\"","title":"Version"},{"location":"reference/minotaor/version/#module-minotaorversion","text":"View Source __version__ = \"0.1.2\"","title":"Module minotaor.version"}]}